{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KHDS_Keras_sklearn_4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfEFWjuHzeGL+DnbNgKk/n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/THESHAMIK/Real-Life-Projects/blob/main/Deep_NN/KHDS_Keras_sklearn_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5clfgvrJzuZ"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "#from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
        "from tensorflow.keras.optimizers import Adam ##because cannot import name 'Adam' from 'keras.optimizers'\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from math import floor\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "#from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.layers import LeakyReLU\n",
        "LeakyReLU = LeakyReLU(alpha=0.1)\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"khds_final_1.csv\")\n",
        "df['Product Sulphur'] = pd.to_numeric(df['Product Sulphur'],errors = 'coerce') ##==> This one works as pd.to_numeric works for convert a list, a series, an array, or a tuple to a numeric datatype\n",
        "filtered_df = df[df['Product Sulphur'].notnull()]\n",
        "df.dropna(axis=0)\n",
        "filtered_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZR4JZ1nJ4cH",
        "outputId": "7d9cffce-7f85-49d5-979e-7319f45f181b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 709 entries, 0 to 710\n",
            "Data columns (total 34 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   LABfeed Sulphur                            709 non-null    float64\n",
            " 1   T1 : FRESH FEED FLOW TO KHDS KGPerHour     709 non-null    float64\n",
            " 2   T1 : Reactor inlet temperature DEGC        709 non-null    float64\n",
            " 3   T1 : Hydrogen make-up flow NM3perHour      709 non-null    float64\n",
            " 4   T1 : Recycle hydrogen flow NM3perHour      709 non-null    float64\n",
            " 5   T1 : REACTOR OUTLET Temp DEGC              709 non-null    float64\n",
            " 6   T1 : REACTOR FEED INLET Pressure KGperCM2  709 non-null    float64\n",
            " 7   T1 : Cold separator pressure KGperCM2      709 non-null    float64\n",
            " 8   T1 : KERO FEED DENSITY KGperCM2            709 non-null    float64\n",
            " 9   T2 : FRESH FEED FLOW TO KHDS KGPerHour     709 non-null    float64\n",
            " 10  T2 : Reactor inlet temperature DEGC        709 non-null    float64\n",
            " 11  T2 : Hydrogen make-up flow NM3perHour      709 non-null    float64\n",
            " 12  T2 : Recycle hydrogen flow NM3perHour      709 non-null    float64\n",
            " 13  T2 : REACTOR OUTLET Temp DEGC              709 non-null    float64\n",
            " 14  T2 : REACTOR FEED INLET Pressure KGperCM2  709 non-null    float64\n",
            " 15  T2 : Cold separator pressure KGperCM2      709 non-null    float64\n",
            " 16  T2 : KERO FEED DENSITY KGperCM2            709 non-null    float64\n",
            " 17  T3 : FRESH FEED FLOW TO KHDS KGPerHour     709 non-null    float64\n",
            " 18  T3 : Reactor inlet temperature DEGC        709 non-null    float64\n",
            " 19  T3 : Hydrogen make-up flow NM3perHour      709 non-null    float64\n",
            " 20  T3 : Recycle hydrogen flow NM3perHour      709 non-null    float64\n",
            " 21  T3 : REACTOR OUTLET Temp DEGC              709 non-null    float64\n",
            " 22  T3 : REACTOR FEED INLET Pressure KGperCM2  709 non-null    float64\n",
            " 23  T3 : Cold separator pressure KGperCM2      709 non-null    float64\n",
            " 24  T3 : KERO FEED DENSITY KGperCM2            709 non-null    float64\n",
            " 25  T4 : FRESH FEED FLOW TO KHDS KGPerHour     709 non-null    float64\n",
            " 26  T4 : Reactor inlet temperature DEGC        709 non-null    float64\n",
            " 27  T4 : Hydrogen make-up flow NM3perHour      709 non-null    float64\n",
            " 28  T4 : Recycle hydrogen flow NM3perHour      709 non-null    float64\n",
            " 29  T4 : REACTOR OUTLET Temp DEGC              709 non-null    float64\n",
            " 30  T4 : REACTOR FEED INLET Pressure KGperCM2  709 non-null    float64\n",
            " 31  T4 : Cold separator pressure KGperCM2      709 non-null    float64\n",
            " 32  T4 : KERO FEED DENSITY KGperCM2            709 non-null    float64\n",
            " 33  Product Sulphur                            709 non-null    float64\n",
            "dtypes: float64(34)\n",
            "memory usage: 193.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = \"Product Sulphur\"\n",
        "X = filtered_df.loc[:, filtered_df.columns != target_col]\n",
        "y = filtered_df.loc[:, target_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.20, \n",
        "                                                    random_state=2021)"
      ],
      "metadata": {
        "id": "jkgnvry8J-Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"XTRAIN :: ytrain shapes::\"+ str(X_train.shape + y_train.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-GvqrmWKGkZ",
        "outputId": "3a9a2c05-583a-4ae6-d472-f6d28219ac2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XTRAIN :: ytrain shapes::(567, 33, 567)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "EE7qR-OTKMoP",
        "outputId": "be5b0426-79db-440a-b197-07e375e73737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     LABfeed Sulphur  T1 : FRESH FEED FLOW TO KHDS KGPerHour  \\\n",
              "419           2000.0                             86021.90109   \n",
              "642           1700.0                             72443.19286   \n",
              "249           2000.0                             75523.03776   \n",
              "708           1200.0                             60425.38188   \n",
              "335           2500.0                             37334.09186   \n",
              "\n",
              "     T1 : Reactor inlet temperature DEGC  \\\n",
              "419                           295.013961   \n",
              "642                           292.066222   \n",
              "249                           290.943491   \n",
              "708                           270.062989   \n",
              "335                           283.631855   \n",
              "\n",
              "     T1 : Hydrogen make-up flow NM3perHour  \\\n",
              "419                             805.301728   \n",
              "642                             752.980982   \n",
              "249                             773.181403   \n",
              "708                             528.413451   \n",
              "335                             465.162410   \n",
              "\n",
              "     T1 : Recycle hydrogen flow NM3perHour  T1 : REACTOR OUTLET Temp DEGC  \\\n",
              "419                            14895.57788                     295.551416   \n",
              "642                            15886.25013                     293.512951   \n",
              "249                            14760.76771                     292.549527   \n",
              "708                            12517.83553                     272.306049   \n",
              "335                            10073.34530                     287.435755   \n",
              "\n",
              "     T1 : REACTOR FEED INLET Pressure KGperCM2  \\\n",
              "419                                  22.581979   \n",
              "642                                  22.153329   \n",
              "249                                  22.036806   \n",
              "708                                  21.014648   \n",
              "335                                  20.057154   \n",
              "\n",
              "     T1 : Cold separator pressure KGperCM2  T1 : KERO FEED DENSITY KGperCM2  \\\n",
              "419                              18.585012                       689.166864   \n",
              "642                              18.614115                       694.906073   \n",
              "249                              18.592275                       701.499601   \n",
              "708                              18.605937                       693.293790   \n",
              "335                              18.626658                       720.123723   \n",
              "\n",
              "     T2 : FRESH FEED FLOW TO KHDS KGPerHour  \\\n",
              "419                             85617.90755   \n",
              "642                             72445.54081   \n",
              "249                             75131.92813   \n",
              "708                             60522.48813   \n",
              "335                             37452.27415   \n",
              "\n",
              "     T2 : Reactor inlet temperature DEGC  \\\n",
              "419                           295.091414   \n",
              "642                           292.151484   \n",
              "249                           291.092579   \n",
              "708                           269.937830   \n",
              "335                           283.548467   \n",
              "\n",
              "     T2 : Hydrogen make-up flow NM3perHour  \\\n",
              "419                             845.412662   \n",
              "642                             804.601129   \n",
              "249                             760.499984   \n",
              "708                             543.695607   \n",
              "335                             483.524894   \n",
              "\n",
              "     T2 : Recycle hydrogen flow NM3perHour  T2 : REACTOR OUTLET Temp DEGC  \\\n",
              "419                            14878.67527                     295.836288   \n",
              "642                            15839.85134                     293.845743   \n",
              "249                            14598.56227                     292.442571   \n",
              "708                            12538.70984                     272.363892   \n",
              "335                            10144.56602                     287.446968   \n",
              "\n",
              "     T2 : REACTOR FEED INLET Pressure KGperCM2  \\\n",
              "419                                  22.604003   \n",
              "642                                  22.155323   \n",
              "249                                  22.042040   \n",
              "708                                  21.024867   \n",
              "335                                  20.061056   \n",
              "\n",
              "     T2 : Cold separator pressure KGperCM2  T2 : KERO FEED DENSITY KGperCM2  \\\n",
              "419                              18.607992                       688.805922   \n",
              "642                              18.625997                       695.113605   \n",
              "249                              18.613078                       702.685225   \n",
              "708                              18.610148                       693.428608   \n",
              "335                              18.625387                       720.097691   \n",
              "\n",
              "     T3 : FRESH FEED FLOW TO KHDS KGPerHour  \\\n",
              "419                             86099.48667   \n",
              "642                             72516.25104   \n",
              "249                             75257.05573   \n",
              "708                             60362.94141   \n",
              "335                             37306.37070   \n",
              "\n",
              "     T3 : Reactor inlet temperature DEGC  \\\n",
              "419                           294.993230   \n",
              "642                           292.124805   \n",
              "249                           291.065754   \n",
              "708                           270.056110   \n",
              "335                           283.656686   \n",
              "\n",
              "     T3 : Hydrogen make-up flow NM3perHour  \\\n",
              "419                             844.489997   \n",
              "642                             769.015451   \n",
              "249                             783.945437   \n",
              "708                             533.556605   \n",
              "335                             467.344424   \n",
              "\n",
              "     T3 : Recycle hydrogen flow NM3perHour  T3 : REACTOR OUTLET Temp DEGC  \\\n",
              "419                            14940.19203                     295.796407   \n",
              "642                            15865.79212                     293.407692   \n",
              "249                            14528.38252                     292.734528   \n",
              "708                            12546.30783                     272.405243   \n",
              "335                            10192.75400                     287.319540   \n",
              "\n",
              "     T3 : REACTOR FEED INLET Pressure KGperCM2  \\\n",
              "419                                  22.607123   \n",
              "642                                  22.130655   \n",
              "249                                  22.021091   \n",
              "708                                  21.015765   \n",
              "335                                  20.052672   \n",
              "\n",
              "     T3 : Cold separator pressure KGperCM2  T3 : KERO FEED DENSITY KGperCM2  \\\n",
              "419                              18.599091                       689.164303   \n",
              "642                              18.591639                       695.073172   \n",
              "249                              18.590698                       702.814941   \n",
              "708                              18.600281                       693.736376   \n",
              "335                              18.623301                       719.745461   \n",
              "\n",
              "     T4 : FRESH FEED FLOW TO KHDS KGPerHour  \\\n",
              "419                             86460.01260   \n",
              "642                             72126.96383   \n",
              "249                             75335.43776   \n",
              "708                             60353.13302   \n",
              "335                             37132.63086   \n",
              "\n",
              "     T4 : Reactor inlet temperature DEGC  \\\n",
              "419                           295.031797   \n",
              "642                           291.817534   \n",
              "249                           291.093012   \n",
              "708                           270.083814   \n",
              "335                           283.715846   \n",
              "\n",
              "     T4 : Hydrogen make-up flow NM3perHour  \\\n",
              "419                             817.443504   \n",
              "642                             769.062447   \n",
              "249                             789.142989   \n",
              "708                             536.398630   \n",
              "335                             478.964552   \n",
              "\n",
              "     T4 : Recycle hydrogen flow NM3perHour  T4 : REACTOR OUTLET Temp DEGC  \\\n",
              "419                            14949.43041                     295.922666   \n",
              "642                            15889.80355                     293.563373   \n",
              "249                            14536.62181                     292.956879   \n",
              "708                            12618.29635                     272.570469   \n",
              "335                            10192.00311                     287.291786   \n",
              "\n",
              "     T4 : REACTOR FEED INLET Pressure KGperCM2  \\\n",
              "419                                  22.601837   \n",
              "642                                  22.152541   \n",
              "249                                  22.051083   \n",
              "708                                  21.040742   \n",
              "335                                  20.048456   \n",
              "\n",
              "     T4 : Cold separator pressure KGperCM2  T4 : KERO FEED DENSITY KGperCM2  \n",
              "419                              18.592478                       688.712130  \n",
              "642                              18.606115                       695.372522  \n",
              "249                              18.606669                       702.206163  \n",
              "708                              18.611755                       693.730737  \n",
              "335                              18.608933                       719.036873  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af0613e8-653d-4bb5-810d-b0e9d8fc2ad0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABfeed Sulphur</th>\n",
              "      <th>T1 : FRESH FEED FLOW TO KHDS KGPerHour</th>\n",
              "      <th>T1 : Reactor inlet temperature DEGC</th>\n",
              "      <th>T1 : Hydrogen make-up flow NM3perHour</th>\n",
              "      <th>T1 : Recycle hydrogen flow NM3perHour</th>\n",
              "      <th>T1 : REACTOR OUTLET Temp DEGC</th>\n",
              "      <th>T1 : REACTOR FEED INLET Pressure KGperCM2</th>\n",
              "      <th>T1 : Cold separator pressure KGperCM2</th>\n",
              "      <th>T1 : KERO FEED DENSITY KGperCM2</th>\n",
              "      <th>T2 : FRESH FEED FLOW TO KHDS KGPerHour</th>\n",
              "      <th>T2 : Reactor inlet temperature DEGC</th>\n",
              "      <th>T2 : Hydrogen make-up flow NM3perHour</th>\n",
              "      <th>T2 : Recycle hydrogen flow NM3perHour</th>\n",
              "      <th>T2 : REACTOR OUTLET Temp DEGC</th>\n",
              "      <th>T2 : REACTOR FEED INLET Pressure KGperCM2</th>\n",
              "      <th>T2 : Cold separator pressure KGperCM2</th>\n",
              "      <th>T2 : KERO FEED DENSITY KGperCM2</th>\n",
              "      <th>T3 : FRESH FEED FLOW TO KHDS KGPerHour</th>\n",
              "      <th>T3 : Reactor inlet temperature DEGC</th>\n",
              "      <th>T3 : Hydrogen make-up flow NM3perHour</th>\n",
              "      <th>T3 : Recycle hydrogen flow NM3perHour</th>\n",
              "      <th>T3 : REACTOR OUTLET Temp DEGC</th>\n",
              "      <th>T3 : REACTOR FEED INLET Pressure KGperCM2</th>\n",
              "      <th>T3 : Cold separator pressure KGperCM2</th>\n",
              "      <th>T3 : KERO FEED DENSITY KGperCM2</th>\n",
              "      <th>T4 : FRESH FEED FLOW TO KHDS KGPerHour</th>\n",
              "      <th>T4 : Reactor inlet temperature DEGC</th>\n",
              "      <th>T4 : Hydrogen make-up flow NM3perHour</th>\n",
              "      <th>T4 : Recycle hydrogen flow NM3perHour</th>\n",
              "      <th>T4 : REACTOR OUTLET Temp DEGC</th>\n",
              "      <th>T4 : REACTOR FEED INLET Pressure KGperCM2</th>\n",
              "      <th>T4 : Cold separator pressure KGperCM2</th>\n",
              "      <th>T4 : KERO FEED DENSITY KGperCM2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>86021.90109</td>\n",
              "      <td>295.013961</td>\n",
              "      <td>805.301728</td>\n",
              "      <td>14895.57788</td>\n",
              "      <td>295.551416</td>\n",
              "      <td>22.581979</td>\n",
              "      <td>18.585012</td>\n",
              "      <td>689.166864</td>\n",
              "      <td>85617.90755</td>\n",
              "      <td>295.091414</td>\n",
              "      <td>845.412662</td>\n",
              "      <td>14878.67527</td>\n",
              "      <td>295.836288</td>\n",
              "      <td>22.604003</td>\n",
              "      <td>18.607992</td>\n",
              "      <td>688.805922</td>\n",
              "      <td>86099.48667</td>\n",
              "      <td>294.993230</td>\n",
              "      <td>844.489997</td>\n",
              "      <td>14940.19203</td>\n",
              "      <td>295.796407</td>\n",
              "      <td>22.607123</td>\n",
              "      <td>18.599091</td>\n",
              "      <td>689.164303</td>\n",
              "      <td>86460.01260</td>\n",
              "      <td>295.031797</td>\n",
              "      <td>817.443504</td>\n",
              "      <td>14949.43041</td>\n",
              "      <td>295.922666</td>\n",
              "      <td>22.601837</td>\n",
              "      <td>18.592478</td>\n",
              "      <td>688.712130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642</th>\n",
              "      <td>1700.0</td>\n",
              "      <td>72443.19286</td>\n",
              "      <td>292.066222</td>\n",
              "      <td>752.980982</td>\n",
              "      <td>15886.25013</td>\n",
              "      <td>293.512951</td>\n",
              "      <td>22.153329</td>\n",
              "      <td>18.614115</td>\n",
              "      <td>694.906073</td>\n",
              "      <td>72445.54081</td>\n",
              "      <td>292.151484</td>\n",
              "      <td>804.601129</td>\n",
              "      <td>15839.85134</td>\n",
              "      <td>293.845743</td>\n",
              "      <td>22.155323</td>\n",
              "      <td>18.625997</td>\n",
              "      <td>695.113605</td>\n",
              "      <td>72516.25104</td>\n",
              "      <td>292.124805</td>\n",
              "      <td>769.015451</td>\n",
              "      <td>15865.79212</td>\n",
              "      <td>293.407692</td>\n",
              "      <td>22.130655</td>\n",
              "      <td>18.591639</td>\n",
              "      <td>695.073172</td>\n",
              "      <td>72126.96383</td>\n",
              "      <td>291.817534</td>\n",
              "      <td>769.062447</td>\n",
              "      <td>15889.80355</td>\n",
              "      <td>293.563373</td>\n",
              "      <td>22.152541</td>\n",
              "      <td>18.606115</td>\n",
              "      <td>695.372522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>75523.03776</td>\n",
              "      <td>290.943491</td>\n",
              "      <td>773.181403</td>\n",
              "      <td>14760.76771</td>\n",
              "      <td>292.549527</td>\n",
              "      <td>22.036806</td>\n",
              "      <td>18.592275</td>\n",
              "      <td>701.499601</td>\n",
              "      <td>75131.92813</td>\n",
              "      <td>291.092579</td>\n",
              "      <td>760.499984</td>\n",
              "      <td>14598.56227</td>\n",
              "      <td>292.442571</td>\n",
              "      <td>22.042040</td>\n",
              "      <td>18.613078</td>\n",
              "      <td>702.685225</td>\n",
              "      <td>75257.05573</td>\n",
              "      <td>291.065754</td>\n",
              "      <td>783.945437</td>\n",
              "      <td>14528.38252</td>\n",
              "      <td>292.734528</td>\n",
              "      <td>22.021091</td>\n",
              "      <td>18.590698</td>\n",
              "      <td>702.814941</td>\n",
              "      <td>75335.43776</td>\n",
              "      <td>291.093012</td>\n",
              "      <td>789.142989</td>\n",
              "      <td>14536.62181</td>\n",
              "      <td>292.956879</td>\n",
              "      <td>22.051083</td>\n",
              "      <td>18.606669</td>\n",
              "      <td>702.206163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>708</th>\n",
              "      <td>1200.0</td>\n",
              "      <td>60425.38188</td>\n",
              "      <td>270.062989</td>\n",
              "      <td>528.413451</td>\n",
              "      <td>12517.83553</td>\n",
              "      <td>272.306049</td>\n",
              "      <td>21.014648</td>\n",
              "      <td>18.605937</td>\n",
              "      <td>693.293790</td>\n",
              "      <td>60522.48813</td>\n",
              "      <td>269.937830</td>\n",
              "      <td>543.695607</td>\n",
              "      <td>12538.70984</td>\n",
              "      <td>272.363892</td>\n",
              "      <td>21.024867</td>\n",
              "      <td>18.610148</td>\n",
              "      <td>693.428608</td>\n",
              "      <td>60362.94141</td>\n",
              "      <td>270.056110</td>\n",
              "      <td>533.556605</td>\n",
              "      <td>12546.30783</td>\n",
              "      <td>272.405243</td>\n",
              "      <td>21.015765</td>\n",
              "      <td>18.600281</td>\n",
              "      <td>693.736376</td>\n",
              "      <td>60353.13302</td>\n",
              "      <td>270.083814</td>\n",
              "      <td>536.398630</td>\n",
              "      <td>12618.29635</td>\n",
              "      <td>272.570469</td>\n",
              "      <td>21.040742</td>\n",
              "      <td>18.611755</td>\n",
              "      <td>693.730737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>2500.0</td>\n",
              "      <td>37334.09186</td>\n",
              "      <td>283.631855</td>\n",
              "      <td>465.162410</td>\n",
              "      <td>10073.34530</td>\n",
              "      <td>287.435755</td>\n",
              "      <td>20.057154</td>\n",
              "      <td>18.626658</td>\n",
              "      <td>720.123723</td>\n",
              "      <td>37452.27415</td>\n",
              "      <td>283.548467</td>\n",
              "      <td>483.524894</td>\n",
              "      <td>10144.56602</td>\n",
              "      <td>287.446968</td>\n",
              "      <td>20.061056</td>\n",
              "      <td>18.625387</td>\n",
              "      <td>720.097691</td>\n",
              "      <td>37306.37070</td>\n",
              "      <td>283.656686</td>\n",
              "      <td>467.344424</td>\n",
              "      <td>10192.75400</td>\n",
              "      <td>287.319540</td>\n",
              "      <td>20.052672</td>\n",
              "      <td>18.623301</td>\n",
              "      <td>719.745461</td>\n",
              "      <td>37132.63086</td>\n",
              "      <td>283.715846</td>\n",
              "      <td>478.964552</td>\n",
              "      <td>10192.00311</td>\n",
              "      <td>287.291786</td>\n",
              "      <td>20.048456</td>\n",
              "      <td>18.608933</td>\n",
              "      <td>719.036873</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af0613e8-653d-4bb5-810d-b0e9d8fc2ad0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af0613e8-653d-4bb5-810d-b0e9d8fc2ad0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af0613e8-653d-4bb5-810d-b0e9d8fc2ad0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale data, otherwise model will fail.\n",
        "#Standardize features by removing the mean and scaling to unit variance\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "dJSAjAPYKRN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4zkUf9_KgWi",
        "outputId": "248be621-bde4-47df-e7c1-38ad8de9498f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFowQevhK29g",
        "outputId": "39200199-34a7-4d57-97b6-1df35c50b8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled.view()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD4Smq8tLCD3",
        "outputId": "4d13bd2e-96be-49e7-e29f-79a9d90b4574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.53407746,  0.9658201 ,  0.37290493, ...,  0.57395306,\n",
              "         0.10508062,  0.20690118],\n",
              "       [-0.17561927,  0.38341511,  0.27669157, ...,  0.37972304,\n",
              "         0.11224147,  0.24259106],\n",
              "       [ 0.53407746,  0.51551288,  0.24004593, ...,  0.33586308,\n",
              "         0.11253261,  0.2792093 ],\n",
              "       ...,\n",
              "       [ 0.53407746, -0.91307536, -0.03197214, ..., -0.59240925,\n",
              "         0.12403911,  0.25970944],\n",
              "       [ 0.53407746,  0.40962512,  0.32385226, ...,  0.37672823,\n",
              "         0.10402559,  0.3108514 ],\n",
              "       [-1.35844716, -1.4196743 , -0.61528425, ..., -0.63458177,\n",
              "         0.060748  ,  0.32228763]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to review this later why some of values r negative? Looks like LAB Feed is negative?"
      ],
      "metadata": {
        "id": "x8SgmNsKLpLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2zD_LQbL6C3",
        "outputId": "693e56b0-e9fa-453c-a5a7-23407d56c652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(567, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning for learning rate ==> https://www.youtube.com/watch?v=qk9gUCdb3aw 187."
      ],
      "metadata": {
        "id": "aoNgpQ42Ms3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdhz29MnMVa-",
        "outputId": "36972383-4c4b-4cdd-982b-db58ba63376f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n",
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model_1(learning_rate=0.01):   \n",
        "    model1 = Sequential()\n",
        "    model1.add(Dense(64, activation='relu', kernel_initializer='uniform', \n",
        "                    input_dim = 33)) \n",
        "    model1.add(Dropout(0.1))\n",
        "    model1.add(Dense(64, kernel_initializer='uniform', activation='relu'))\n",
        "    model1.add(Dense(1, kernel_initializer='uniform'))\n",
        "    optimizer = Adam(lr=learning_rate)\n",
        "    # compile the model\n",
        "    model1.compile(loss='mse',\n",
        "                  optimizer=optimizer,      \n",
        "                  metrics=['mae'])\n",
        "    return model1"
      ],
      "metadata": {
        "id": "aqSivLQRNIwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "epochs = 10\n",
        "learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
        "model11 = KerasRegressor(build_fn=define_model_1, \n",
        "                        epochs=epochs, \n",
        "                        batch_size = batch_size, \n",
        "                        verbose=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "Oqnf_C5wNs16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = dict(learning_rate=learning_rate)\n",
        "grid = GridSearchCV(estimator=model11, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FItSKa86OAlM",
        "outputId": "47a9340d-a7f7-4d49-8a77-502fe5f02da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 364014.0938 - mae: 320.1018\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 2493.9902 - mae: 43.2060\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 766.6806 - mae: 22.3299\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 368.9601 - mae: 16.6321\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 142.6519 - mae: 9.9654\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 99.9079 - mae: 8.3649\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 45.5371 - mae: 5.0992\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 39.1110 - mae: 4.8581\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 24.0254 - mae: 3.4475\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 20.1046 - mae: 2.9403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WS0FE3-Os_9",
        "outputId": "2b9ccaeb-e9a6-4147-eff8-8d543d360058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: -24.619279 using {'learning_rate': 0.01}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result = grid.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kge7NUR0OxFH",
        "outputId": "909c06b1-da4e-4d0b-9289-27f77c31b23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 26.2990 - mae: 3.6740\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 17.3185 - mae: 2.4918\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 15.3877 - mae: 1.9478\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 14.0390 - mae: 1.9740\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 13.4874 - mae: 2.0425\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 12.5785 - mae: 1.8933\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 12.0447 - mae: 1.8312\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 11.7117 - mae: 1.7944\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 11.3684 - mae: 1.8973\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 10.9890 - mae: 1.7312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LChYdcWO7tu",
        "outputId": "dcd8fdf8-43c3-43e3-b103-3467556fc6c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: -11.919380 using {'learning_rate': 0.01}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2lCl_vXaRRZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SO LEARNING rate is freezed to 0.01 whether data scaled or not.\n",
        "\n",
        "loss: 20.1046 - mae: 2.9403 for UNSCALED data.\n",
        "loss: 10.9890 - mae: 1.7312 for SCALED data."
      ],
      "metadata": {
        "id": "rTLKt_XaPAOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model_2(activation='relu', init_weights='uniform', optimizer='Adam'):   \n",
        "    model2 = Sequential()\n",
        "    model2.add(Dense(64, activation=activation, kernel_initializer=init_weights, \n",
        "                    input_dim = 33)) \n",
        "    model2.add(Dropout(0.1))\n",
        "    model2.add(Dense(64, kernel_initializer=init_weights, activation=activation))\n",
        "    model2.add(Dense(1, kernel_initializer=init_weights))\n",
        "    \n",
        "    # compile the model\n",
        "    model2.compile(loss='mean_squared_error',\n",
        "                  optimizer=optimizer,      \n",
        "                  metrics=['mae'])\n",
        "    return model2"
      ],
      "metadata": {
        "id": "B9fj79nzPFdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/bnsreenu/python_for_microscopists/blob/master/188-gridsearch_hyperparam_tuning_activation_opt_weights.py "
      ],
      "metadata": {
        "id": "SAJyw32xQYa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "epochs = 10\n",
        "\n",
        "model22 = KerasRegressor(build_fn=define_model_2, \n",
        "                        epochs=epochs, \n",
        "                        batch_size = batch_size, \n",
        "                        verbose=1)\n"
      ],
      "metadata": {
        "id": "2C8iQwOHQJtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation = ['tanh', 'relu', 'sigmoid']\n",
        "#Also try softplus, tanh, linear, hard_sigmoid \n",
        "init_weights = ['uniform', 'normal', 'he_uniform']\n",
        "#Also try lecun_uniform, he_normal, glorot_normal, etc. \n",
        "optimizer = ['SGD', 'RMSprop', 'Adam']\n",
        "\n",
        "param_grid = dict(activation=activation, init_weights=init_weights, optimizer=optimizer)\n",
        "\n",
        "#n_jobs=16 uses 16 CPUs. Try not to do -1 on your system as it may hang!!!\n",
        "# -1 refers to using all available CPUs\n",
        "#Cross validation, cv=3\n",
        "grid22 = GridSearchCV(estimator=model22, param_grid=param_grid, n_jobs=-1, cv=3)"
      ],
      "metadata": {
        "id": "-fxthKpQQWnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result22 = grid22.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj_GzLAdQ2iu",
        "outputId": "a503f519-300b-47c2-9ab9-0b6b68c998f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 15.2126 - mae: 2.4931\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 12.6972 - mae: 2.0434\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 13.3538 - mae: 2.2473\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 12.8191 - mae: 2.0705\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 13.1938 - mae: 2.1557\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 12.5246 - mae: 2.0466\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 12.4706 - mae: 2.0684\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 12.6740 - mae: 2.0517\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 12.7780 - mae: 2.0711\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 12.5696 - mae: 2.0484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result22.best_score_, grid_result22.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC1bS837RSSf",
        "outputId": "3426d340-17c9-4486-f95e-e4ccab279081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: -12.269863 using {'activation': 'tanh', 'init_weights': 'he_uniform', 'optimizer': 'SGD'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result22_s = grid22.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mfq02bGRabn",
        "outputId": "4ab2e3b1-dc50-40cb-bcea-b4df1169b65f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 24.6507 - mae: 3.4538\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 16.2426 - mae: 2.2368\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 12.9254 - mae: 1.8801\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 12.1461 - mae: 1.8745\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 11.6375 - mae: 1.8200\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 11.2114 - mae: 1.8085\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 10.9633 - mae: 1.8997\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 10.4907 - mae: 1.7699\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 10.3919 - mae: 1.7471\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 10.5053 - mae: 1.7871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result22_s.best_score_, grid_result22_s.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35PQnYuORyLo",
        "outputId": "5e096afc-29ef-49e7-962a-485528955d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: -11.405379 using {'activation': 'tanh', 'init_weights': 'he_uniform', 'optimizer': 'SGD'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "epochs = 200\n",
        "\n",
        "model22_m = KerasRegressor(build_fn=define_model_2, \n",
        "                        epochs=epochs, \n",
        "                        batch_size = batch_size, \n",
        "                        verbose=1)\n",
        "grid22_m = GridSearchCV(estimator=model22_m, param_grid=param_grid, n_jobs=-1, cv=5)\n",
        "grid_result22_m = grid22_m.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RukQwcrlSqgp",
        "outputId": "1f92e2da-5cb4-490c-dfff-6c1f951a9dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "57/57 [==============================] - 1s 2ms/step - loss: 18.4032 - mae: 2.6132\n",
            "Epoch 2/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9287 - mae: 2.1007\n",
            "Epoch 3/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9203 - mae: 2.0855\n",
            "Epoch 4/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8468 - mae: 2.0676\n",
            "Epoch 5/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8719 - mae: 2.1336\n",
            "Epoch 6/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8719 - mae: 2.0843\n",
            "Epoch 7/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9798 - mae: 2.0827\n",
            "Epoch 8/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8430 - mae: 2.0983\n",
            "Epoch 9/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8745 - mae: 2.0568\n",
            "Epoch 10/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9091 - mae: 2.1224\n",
            "Epoch 11/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9243 - mae: 2.1094\n",
            "Epoch 12/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8340 - mae: 2.1538\n",
            "Epoch 13/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 13.0037 - mae: 2.0827\n",
            "Epoch 14/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8436 - mae: 2.0491\n",
            "Epoch 15/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8876 - mae: 2.1418\n",
            "Epoch 16/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8280 - mae: 2.0776\n",
            "Epoch 17/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9209 - mae: 2.0902\n",
            "Epoch 18/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8610 - mae: 2.0633\n",
            "Epoch 19/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9956 - mae: 2.0862\n",
            "Epoch 20/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8574 - mae: 2.1261\n",
            "Epoch 21/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9979 - mae: 2.1077\n",
            "Epoch 22/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9089 - mae: 2.0951\n",
            "Epoch 23/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9406 - mae: 2.0785\n",
            "Epoch 24/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9013 - mae: 2.1060\n",
            "Epoch 25/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8451 - mae: 2.1166\n",
            "Epoch 26/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9179 - mae: 2.0900\n",
            "Epoch 27/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9127 - mae: 2.1092\n",
            "Epoch 28/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9378 - mae: 2.0972\n",
            "Epoch 29/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9026 - mae: 2.0887\n",
            "Epoch 30/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8693 - mae: 2.0768\n",
            "Epoch 31/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9338 - mae: 2.0888\n",
            "Epoch 32/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8422 - mae: 2.1074\n",
            "Epoch 33/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8818 - mae: 2.1288\n",
            "Epoch 34/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9182 - mae: 2.1001\n",
            "Epoch 35/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8535 - mae: 2.0570\n",
            "Epoch 36/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9708 - mae: 2.1346\n",
            "Epoch 37/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9022 - mae: 2.0626\n",
            "Epoch 38/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9383 - mae: 2.1480\n",
            "Epoch 39/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9436 - mae: 2.0594\n",
            "Epoch 40/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8602 - mae: 2.1112\n",
            "Epoch 41/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8770 - mae: 2.1218\n",
            "Epoch 42/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8731 - mae: 2.0746\n",
            "Epoch 43/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8963 - mae: 2.0584\n",
            "Epoch 44/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9596 - mae: 2.1822\n",
            "Epoch 45/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8473 - mae: 2.0489\n",
            "Epoch 46/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9008 - mae: 2.1194\n",
            "Epoch 47/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8667 - mae: 2.1033\n",
            "Epoch 48/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9382 - mae: 2.1216\n",
            "Epoch 49/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9604 - mae: 2.0845\n",
            "Epoch 50/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8952 - mae: 2.0542\n",
            "Epoch 51/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8597 - mae: 2.1339\n",
            "Epoch 52/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9685 - mae: 2.0722\n",
            "Epoch 53/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9556 - mae: 2.1008\n",
            "Epoch 54/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9285 - mae: 2.1026\n",
            "Epoch 55/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8866 - mae: 2.1089\n",
            "Epoch 56/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8504 - mae: 2.0644\n",
            "Epoch 57/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 13.0350 - mae: 2.0988\n",
            "Epoch 58/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8388 - mae: 2.1157\n",
            "Epoch 59/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9010 - mae: 2.1231\n",
            "Epoch 60/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9929 - mae: 2.0872\n",
            "Epoch 61/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8781 - mae: 2.0800\n",
            "Epoch 62/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9006 - mae: 2.1232\n",
            "Epoch 63/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9429 - mae: 2.0673\n",
            "Epoch 64/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8780 - mae: 2.1296\n",
            "Epoch 65/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9064 - mae: 2.0393\n",
            "Epoch 66/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8588 - mae: 2.1117\n",
            "Epoch 67/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8927 - mae: 2.0805\n",
            "Epoch 68/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9279 - mae: 2.1366\n",
            "Epoch 69/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8527 - mae: 2.0620\n",
            "Epoch 70/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8698 - mae: 2.1015\n",
            "Epoch 71/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8478 - mae: 2.0835\n",
            "Epoch 72/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8838 - mae: 2.1054\n",
            "Epoch 73/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9314 - mae: 2.0830\n",
            "Epoch 74/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9217 - mae: 2.0763\n",
            "Epoch 75/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8765 - mae: 2.0985\n",
            "Epoch 76/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9076 - mae: 2.1239\n",
            "Epoch 77/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8626 - mae: 2.0947\n",
            "Epoch 78/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9486 - mae: 2.1103\n",
            "Epoch 79/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8886 - mae: 2.0758\n",
            "Epoch 80/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8428 - mae: 2.0529\n",
            "Epoch 81/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8636 - mae: 2.1306\n",
            "Epoch 82/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8830 - mae: 2.0811\n",
            "Epoch 83/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9130 - mae: 2.1045\n",
            "Epoch 84/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9028 - mae: 2.0766\n",
            "Epoch 85/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8607 - mae: 2.0920\n",
            "Epoch 86/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8680 - mae: 2.1117\n",
            "Epoch 87/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8948 - mae: 2.0844\n",
            "Epoch 88/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8554 - mae: 2.0593\n",
            "Epoch 89/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8645 - mae: 2.0623\n",
            "Epoch 90/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8986 - mae: 2.1068\n",
            "Epoch 91/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9032 - mae: 2.1065\n",
            "Epoch 92/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8450 - mae: 2.0846\n",
            "Epoch 93/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8973 - mae: 2.1156\n",
            "Epoch 94/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8989 - mae: 2.1194\n",
            "Epoch 95/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8617 - mae: 2.0704\n",
            "Epoch 96/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8759 - mae: 2.0821\n",
            "Epoch 97/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8749 - mae: 2.1173\n",
            "Epoch 98/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8745 - mae: 2.0710\n",
            "Epoch 99/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8948 - mae: 2.1139\n",
            "Epoch 100/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9019 - mae: 2.1170\n",
            "Epoch 101/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8752 - mae: 2.0465\n",
            "Epoch 102/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8348 - mae: 2.0572\n",
            "Epoch 103/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8453 - mae: 2.1442\n",
            "Epoch 104/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8958 - mae: 2.0721\n",
            "Epoch 105/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8518 - mae: 2.0911\n",
            "Epoch 106/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8833 - mae: 2.0705\n",
            "Epoch 107/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8681 - mae: 2.1395\n",
            "Epoch 108/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8914 - mae: 2.0776\n",
            "Epoch 109/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8961 - mae: 2.1056\n",
            "Epoch 110/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8430 - mae: 2.0764\n",
            "Epoch 111/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8640 - mae: 2.0737\n",
            "Epoch 112/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8611 - mae: 2.0874\n",
            "Epoch 113/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8829 - mae: 2.1090\n",
            "Epoch 114/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8905 - mae: 2.0912\n",
            "Epoch 115/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8291 - mae: 2.1045\n",
            "Epoch 116/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8689 - mae: 2.0778\n",
            "Epoch 117/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9106 - mae: 2.0711\n",
            "Epoch 118/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8510 - mae: 2.1182\n",
            "Epoch 119/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8551 - mae: 2.0797\n",
            "Epoch 120/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9099 - mae: 2.0906\n",
            "Epoch 121/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8301 - mae: 2.0958\n",
            "Epoch 122/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8605 - mae: 2.0924\n",
            "Epoch 123/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8779 - mae: 2.0529\n",
            "Epoch 124/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8780 - mae: 2.1008\n",
            "Epoch 125/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8741 - mae: 2.1129\n",
            "Epoch 126/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8588 - mae: 2.0781\n",
            "Epoch 127/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8458 - mae: 2.0685\n",
            "Epoch 128/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8747 - mae: 2.1093\n",
            "Epoch 129/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8675 - mae: 2.0972\n",
            "Epoch 130/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8890 - mae: 2.0823\n",
            "Epoch 131/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8850 - mae: 2.0919\n",
            "Epoch 132/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8988 - mae: 2.1165\n",
            "Epoch 133/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8611 - mae: 2.0864\n",
            "Epoch 134/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8616 - mae: 2.1015\n",
            "Epoch 135/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8451 - mae: 2.0792\n",
            "Epoch 136/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8537 - mae: 2.0988\n",
            "Epoch 137/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8486 - mae: 2.0943\n",
            "Epoch 138/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8769 - mae: 2.0743\n",
            "Epoch 139/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8844 - mae: 2.0957\n",
            "Epoch 140/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8740 - mae: 2.1100\n",
            "Epoch 141/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8758 - mae: 2.1101\n",
            "Epoch 142/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8568 - mae: 2.0631\n",
            "Epoch 143/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8613 - mae: 2.0894\n",
            "Epoch 144/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9219 - mae: 2.1229\n",
            "Epoch 145/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8635 - mae: 2.0438\n",
            "Epoch 146/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8333 - mae: 2.1200\n",
            "Epoch 147/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8722 - mae: 2.0592\n",
            "Epoch 148/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8682 - mae: 2.1204\n",
            "Epoch 149/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8400 - mae: 2.0814\n",
            "Epoch 150/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8596 - mae: 2.0975\n",
            "Epoch 151/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8955 - mae: 2.0904\n",
            "Epoch 152/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8761 - mae: 2.0597\n",
            "Epoch 153/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8568 - mae: 2.1099\n",
            "Epoch 154/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8469 - mae: 2.0651\n",
            "Epoch 155/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8695 - mae: 2.1235\n",
            "Epoch 156/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8852 - mae: 2.0473\n",
            "Epoch 157/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8750 - mae: 2.1339\n",
            "Epoch 158/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8582 - mae: 2.0822\n",
            "Epoch 159/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9409 - mae: 2.0983\n",
            "Epoch 160/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8867 - mae: 2.0900\n",
            "Epoch 161/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8583 - mae: 2.0593\n",
            "Epoch 162/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8617 - mae: 2.1178\n",
            "Epoch 163/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8362 - mae: 2.1077\n",
            "Epoch 164/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9026 - mae: 2.0937\n",
            "Epoch 165/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8794 - mae: 2.0674\n",
            "Epoch 166/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8551 - mae: 2.0817\n",
            "Epoch 167/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8409 - mae: 2.0770\n",
            "Epoch 168/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8458 - mae: 2.0697\n",
            "Epoch 169/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9061 - mae: 2.1081\n",
            "Epoch 170/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8675 - mae: 2.1072\n",
            "Epoch 171/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8526 - mae: 2.0591\n",
            "Epoch 172/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8831 - mae: 2.0740\n",
            "Epoch 173/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8689 - mae: 2.1185\n",
            "Epoch 174/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9158 - mae: 2.0634\n",
            "Epoch 175/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8707 - mae: 2.0985\n",
            "Epoch 176/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8659 - mae: 2.1126\n",
            "Epoch 177/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8754 - mae: 2.0971\n",
            "Epoch 178/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8449 - mae: 2.0774\n",
            "Epoch 179/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8365 - mae: 2.0800\n",
            "Epoch 180/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8901 - mae: 2.0989\n",
            "Epoch 181/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8394 - mae: 2.0764\n",
            "Epoch 182/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8449 - mae: 2.1092\n",
            "Epoch 183/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8915 - mae: 2.1062\n",
            "Epoch 184/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8668 - mae: 2.0876\n",
            "Epoch 185/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8610 - mae: 2.1023\n",
            "Epoch 186/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8648 - mae: 2.1094\n",
            "Epoch 187/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8593 - mae: 2.0379\n",
            "Epoch 188/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8668 - mae: 2.1003\n",
            "Epoch 189/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8395 - mae: 2.1048\n",
            "Epoch 190/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8777 - mae: 2.0951\n",
            "Epoch 191/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9097 - mae: 2.0833\n",
            "Epoch 192/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8658 - mae: 2.1002\n",
            "Epoch 193/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8884 - mae: 2.0753\n",
            "Epoch 194/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8265 - mae: 2.0884\n",
            "Epoch 195/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8473 - mae: 2.0848\n",
            "Epoch 196/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8992 - mae: 2.0881\n",
            "Epoch 197/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8647 - mae: 2.0941\n",
            "Epoch 198/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8228 - mae: 2.0929\n",
            "Epoch 199/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8377 - mae: 2.0737\n",
            "Epoch 200/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.8796 - mae: 2.1045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result22_m.best_score_, grid_result22_m.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBh9_gu-avxz",
        "outputId": "b18d0fcd-ae37-4c13-cca3-2ba899d1dcbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: -12.024594 using {'activation': 'sigmoid', 'init_weights': 'he_uniform', 'optimizer': 'Adam'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When batch = 100, epoch = 10 this was result:\n",
        "Best: -11.405379 using {'activation': 'tanh', 'init_weights': 'he_uniform', 'optimizer': 'SGD'} \n",
        "This changed to below when batch = 10 & epoch = 200 (BUT it took huge time::\n",
        "{'activation': 'sigmoid', 'init_weights': 'he_uniform', 'optimizer': 'Adam'} \n",
        "Still NOT getting relu? We got Adam after increasin epoch though.\n",
        "he_uniform was constant in both cases.\n",
        "\n",
        "Ok then let's try to FIX the ideal batch & epoch first & will then come back!\n",
        "The run for best batch_size/epochs/neurons/dropout_rate etc took 2 hrs run. The scores are::\n",
        "Best: -76.909940 using {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 200, 'neurons': 10, 'weight_constraint': 3}\n",
        "Batch_size again as 10. epochs = 200 - All with GridSearch only.\n"
      ],
      "metadata": {
        "id": "jVr-DaWaa_NU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter tuning for dropout, # neurons, batch size, # epochs, and weight** constraint ==> https://www.youtube.com/watch?v=Bzsxq1JJbbo\n",
        "\n",
        "https://github.com/bnsreenu/python_for_microscopists/blob/master/189-gridsearch_hyperparam_tuning_dropout_wt_constr_hidden_layer_neurons.py"
      ],
      "metadata": {
        "id": "vX2WFt5HcASE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid search hyperparameters - Tuning dropout and weight constraint\n",
        "A weight constraint is an update to the network that checks the size of the weights. \n",
        "If the size exceeds a predefined limit, the weights are rescaled to \n",
        "size below the limit.\n",
        "The maximum norm (maxnorm) is less aggressive than other norms, so preferable.\n",
        "Use GridSearchCV class from scikit-learn\n",
        "Keras models can be used in scikit-learn by wrapping them with \n",
        "the KerasClassifier or KerasRegressor class.\n",
        "In GridSearchCV:\n",
        "n_jobs = -1 --> uses multiple cores (parallelized)\n",
        "n_jobs = 1 --> do not parallelize (do this only if you get an error with -1)"
      ],
      "metadata": {
        "id": "LE3TYGNZcwjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.constraints import maxnorm\n",
        "def define_model_3(dropout_rate=0.0, weight_constraint=0, neurons=10):   \n",
        "    model3 = Sequential()\n",
        "    model3.add(Dense(neurons, activation='relu', kernel_initializer='he_uniform', \n",
        "                    input_dim = 33, kernel_constraint=maxnorm(weight_constraint))) \n",
        "    model3.add(Dropout(dropout_rate))\n",
        "    model3.add(Dense(neurons, kernel_initializer='he_uniform', activation='relu'))\n",
        "    model3.add(Dense(1, kernel_initializer='he_uniform'))\n",
        "    \n",
        "    # compile the model\n",
        "    model3.compile(loss='mean_squared_error',\n",
        "                  optimizer='Adam',      \n",
        "                  metrics=['mae'])\n",
        "    return model3"
      ],
      "metadata": {
        "id": "bedu6m7MbuEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model33 = KerasRegressor(build_fn=define_model_3, \n",
        "                        verbose=1)"
      ],
      "metadata": {
        "id": "wOrlV-6Ic5VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_rate = [0.0, 0.2, 0.4]\n",
        "weight_constraint = [1, 2, 3]\n",
        "neurons = [10, 32, 64]\n",
        "#batch_size = [100, 200, 400]\n",
        "#epochs = [1, 5, 10]\n",
        "#Changing batch/epoch & check result.\n",
        "batch_size = [10, 20, 50]\n",
        "epochs = [50, 100,200]"
      ],
      "metadata": {
        "id": "ADREXeSEdGLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid33 = dict(dropout_rate=dropout_rate, \n",
        "                  weight_constraint=weight_constraint,\n",
        "                  neurons=neurons, batch_size=batch_size, \n",
        "                  epochs=epochs)\n",
        "\n",
        "#n_jobs=16 uses 16 CPUs. Try not to do -1 on your system as it may hang!!!\n",
        "# -1 refers to using all available CPUs\n",
        "#Cross validation, cv=3\n",
        "grid33 = GridSearchCV(estimator=model33, param_grid=param_grid33, n_jobs=-1, cv=5)\n",
        "\n",
        "grid_result33 = grid33.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRGsSd2NdL1k",
        "outputId": "d6ee02f8-4e6a-47b6-c38d-066a9aa4c60a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 108534232.0000 - mae: 9234.1924\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 13481461.0000 - mae: 3401.7466\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 773833.0625 - mae: 681.7130\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 2147355.2500 - mae: 1284.0570\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 2961978.7500 - mae: 1563.4811\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1252490.1250 - mae: 970.7170\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 204641.5469 - mae: 312.2948\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 278559.5000 - mae: 449.1649\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 333957.7500 - mae: 529.8441\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 145621.3125 - mae: 299.8834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result33.best_score_, grid_result33.best_params_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kajamx2XeoOO",
        "outputId": "bf6d8749-c3ce-4ead-a486-364c563a185b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: -445778.532813 using {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 32, 'weight_constraint': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid33_m = dict(dropout_rate=dropout_rate, \n",
        "                  weight_constraint=weight_constraint,\n",
        "                  neurons=neurons, batch_size=batch_size, \n",
        "                  epochs=epochs)\n",
        "\n",
        "#n_jobs=16 uses 16 CPUs. Try not to do -1 on your system as it may hang!!!\n",
        "# -1 refers to using all available CPUs\n",
        "#Cross validation, cv=3\n",
        "grid33_m = GridSearchCV(estimator=model33, param_grid=param_grid33_m, n_jobs=-1, cv=5)\n",
        "\n",
        "grid_result33_m = grid33_m.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7vCPyazev_D",
        "outputId": "dfec949b-1f3e-4435-bd80-27577402e574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "57/57 [==============================] - 1s 2ms/step - loss: 837087232.0000 - mae: 22826.3672\n",
            "Epoch 2/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 264732000.0000 - mae: 12269.7168\n",
            "Epoch 3/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 124645976.0000 - mae: 8565.5850\n",
            "Epoch 4/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 95610552.0000 - mae: 7367.6816\n",
            "Epoch 5/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 77455040.0000 - mae: 6555.2598\n",
            "Epoch 6/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 60624636.0000 - mae: 5641.5991\n",
            "Epoch 7/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 38793072.0000 - mae: 4506.3301\n",
            "Epoch 8/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 34954500.0000 - mae: 4314.6743\n",
            "Epoch 9/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25916632.0000 - mae: 3632.3167\n",
            "Epoch 10/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 26148950.0000 - mae: 3556.7590\n",
            "Epoch 11/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 19997664.0000 - mae: 3049.6489\n",
            "Epoch 12/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16199967.0000 - mae: 2797.0405\n",
            "Epoch 13/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14321913.0000 - mae: 2582.3398\n",
            "Epoch 14/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12458567.0000 - mae: 2467.7756\n",
            "Epoch 15/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10410116.0000 - mae: 2246.2971\n",
            "Epoch 16/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11001749.0000 - mae: 2217.0557\n",
            "Epoch 17/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8015394.5000 - mae: 1942.4863\n",
            "Epoch 18/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8465981.0000 - mae: 1939.7711\n",
            "Epoch 19/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4966361.0000 - mae: 1519.5470\n",
            "Epoch 20/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5942460.0000 - mae: 1604.3773\n",
            "Epoch 21/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5737376.5000 - mae: 1573.0800\n",
            "Epoch 22/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4196937.5000 - mae: 1423.5270\n",
            "Epoch 23/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4057701.5000 - mae: 1348.5387\n",
            "Epoch 24/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3416387.5000 - mae: 1218.0219\n",
            "Epoch 25/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 2619249.7500 - mae: 1096.5701\n",
            "Epoch 26/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 2698244.2500 - mae: 1046.8499\n",
            "Epoch 27/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 2660311.0000 - mae: 1052.8693\n",
            "Epoch 28/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 2234765.7500 - mae: 968.5829\n",
            "Epoch 29/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1852439.0000 - mae: 856.0323\n",
            "Epoch 30/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1921614.3750 - mae: 883.4442\n",
            "Epoch 31/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1247797.2500 - mae: 738.8031\n",
            "Epoch 32/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1279479.1250 - mae: 744.2808\n",
            "Epoch 33/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1193957.3750 - mae: 662.7448\n",
            "Epoch 34/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1508445.8750 - mae: 733.4969\n",
            "Epoch 35/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1605008.7500 - mae: 696.3784\n",
            "Epoch 36/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 985486.2500 - mae: 610.4616\n",
            "Epoch 37/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1426070.3750 - mae: 664.9199\n",
            "Epoch 38/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1425411.1250 - mae: 640.3273\n",
            "Epoch 39/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 897883.3125 - mae: 557.6375\n",
            "Epoch 40/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 888766.8750 - mae: 531.8616\n",
            "Epoch 41/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1017922.5000 - mae: 539.6801\n",
            "Epoch 42/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 768289.6250 - mae: 510.6430\n",
            "Epoch 43/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 574457.0000 - mae: 445.9581\n",
            "Epoch 44/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 774096.0000 - mae: 485.1534\n",
            "Epoch 45/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 980162.2500 - mae: 513.6937\n",
            "Epoch 46/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 987937.6250 - mae: 477.8656\n",
            "Epoch 47/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 537872.5625 - mae: 416.2776\n",
            "Epoch 48/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 514366.5312 - mae: 409.5547\n",
            "Epoch 49/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 361784.5938 - mae: 378.1428\n",
            "Epoch 50/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 561271.2500 - mae: 406.1827\n",
            "Epoch 51/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 504171.6250 - mae: 366.6817\n",
            "Epoch 52/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 408594.4062 - mae: 341.6602\n",
            "Epoch 53/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 395342.4062 - mae: 325.0695\n",
            "Epoch 54/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 337711.9688 - mae: 282.4369\n",
            "Epoch 55/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 270158.4688 - mae: 302.0013\n",
            "Epoch 56/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 193672.4375 - mae: 253.4571\n",
            "Epoch 57/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 247912.3281 - mae: 261.3893\n",
            "Epoch 58/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 279750.0312 - mae: 239.2772\n",
            "Epoch 59/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 264476.7812 - mae: 260.9493\n",
            "Epoch 60/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 188931.2188 - mae: 214.5138\n",
            "Epoch 61/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 272964.5000 - mae: 243.1382\n",
            "Epoch 62/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 121210.3594 - mae: 210.5951\n",
            "Epoch 63/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 209239.1406 - mae: 221.3415\n",
            "Epoch 64/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 173927.8125 - mae: 219.9085\n",
            "Epoch 65/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 123765.5703 - mae: 183.5085\n",
            "Epoch 66/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 162771.6719 - mae: 203.7997\n",
            "Epoch 67/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 100613.7734 - mae: 192.2584\n",
            "Epoch 68/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 115812.4375 - mae: 180.4775\n",
            "Epoch 69/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 86240.3125 - mae: 183.3347\n",
            "Epoch 70/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 81353.9375 - mae: 174.8738\n",
            "Epoch 71/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 123128.7344 - mae: 168.6495\n",
            "Epoch 72/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 186294.3125 - mae: 181.1560\n",
            "Epoch 73/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 86984.0469 - mae: 165.1261\n",
            "Epoch 74/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 87517.7266 - mae: 165.3163\n",
            "Epoch 75/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 59047.1328 - mae: 154.9176\n",
            "Epoch 76/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 139801.5781 - mae: 165.1026\n",
            "Epoch 77/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 200093.1562 - mae: 190.3109\n",
            "Epoch 78/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 125934.9297 - mae: 162.3629\n",
            "Epoch 79/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 117593.5703 - mae: 155.0555\n",
            "Epoch 80/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 74085.8984 - mae: 146.7571\n",
            "Epoch 81/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 65424.9453 - mae: 142.0796\n",
            "Epoch 82/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 116499.6328 - mae: 160.4512\n",
            "Epoch 83/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 41401.4727 - mae: 124.1944\n",
            "Epoch 84/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 85315.9297 - mae: 132.2618\n",
            "Epoch 85/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 74431.8906 - mae: 144.0880\n",
            "Epoch 86/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 115461.6016 - mae: 130.6307\n",
            "Epoch 87/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 109039.2344 - mae: 126.1329\n",
            "Epoch 88/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 65853.6172 - mae: 123.8268\n",
            "Epoch 89/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 56689.6562 - mae: 117.3738\n",
            "Epoch 90/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 23613.8359 - mae: 83.4786\n",
            "Epoch 91/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 37957.6875 - mae: 98.4457\n",
            "Epoch 92/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 35860.9648 - mae: 96.5324\n",
            "Epoch 93/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 55769.6953 - mae: 110.4309\n",
            "Epoch 94/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 92216.6484 - mae: 101.2319\n",
            "Epoch 95/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 88084.4766 - mae: 107.9982\n",
            "Epoch 96/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 34083.0508 - mae: 105.9048\n",
            "Epoch 97/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 45420.3281 - mae: 97.5763\n",
            "Epoch 98/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 58447.1250 - mae: 91.2540\n",
            "Epoch 99/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 54114.7305 - mae: 90.6608\n",
            "Epoch 100/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 20757.6543 - mae: 77.2042\n",
            "Epoch 101/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 24690.1387 - mae: 86.0478\n",
            "Epoch 102/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 31859.9922 - mae: 85.5543\n",
            "Epoch 103/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 28534.3770 - mae: 83.5499\n",
            "Epoch 104/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29839.9336 - mae: 80.9886\n",
            "Epoch 105/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 36018.2578 - mae: 84.8969\n",
            "Epoch 106/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16989.6230 - mae: 72.1022\n",
            "Epoch 107/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 44459.0430 - mae: 81.2800\n",
            "Epoch 108/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 32332.7695 - mae: 85.2384\n",
            "Epoch 109/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 33868.7266 - mae: 80.7638\n",
            "Epoch 110/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29311.4258 - mae: 75.1058\n",
            "Epoch 111/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16279.6826 - mae: 73.4087\n",
            "Epoch 112/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14935.6865 - mae: 71.8002\n",
            "Epoch 113/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16496.3281 - mae: 60.9497\n",
            "Epoch 114/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 26529.0977 - mae: 74.8265\n",
            "Epoch 115/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12853.7441 - mae: 65.5840\n",
            "Epoch 116/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10952.9590 - mae: 64.7358\n",
            "Epoch 117/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 15892.9316 - mae: 72.9777\n",
            "Epoch 118/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11478.3311 - mae: 61.5374\n",
            "Epoch 119/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 34156.6680 - mae: 75.7311\n",
            "Epoch 120/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17783.0352 - mae: 71.4010\n",
            "Epoch 121/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 15186.6475 - mae: 61.5569\n",
            "Epoch 122/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 18751.2324 - mae: 61.1635\n",
            "Epoch 123/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 18619.6680 - mae: 56.8920\n",
            "Epoch 124/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11286.7793 - mae: 56.2476\n",
            "Epoch 125/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7265.9038 - mae: 49.2839\n",
            "Epoch 126/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10731.8418 - mae: 50.7536\n",
            "Epoch 127/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 23942.2188 - mae: 56.6977\n",
            "Epoch 128/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12325.7520 - mae: 50.4678\n",
            "Epoch 129/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14381.1934 - mae: 51.3895\n",
            "Epoch 130/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16393.3145 - mae: 58.0914\n",
            "Epoch 131/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8634.0957 - mae: 49.2720\n",
            "Epoch 132/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9846.2266 - mae: 51.5274\n",
            "Epoch 133/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8823.5479 - mae: 47.2873\n",
            "Epoch 134/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7553.5703 - mae: 47.8076\n",
            "Epoch 135/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 24266.5332 - mae: 50.6265\n",
            "Epoch 136/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 22181.4277 - mae: 48.1315\n",
            "Epoch 137/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9155.1377 - mae: 51.7578\n",
            "Epoch 138/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8465.0137 - mae: 47.5245\n",
            "Epoch 139/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9152.9736 - mae: 48.1451\n",
            "Epoch 140/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8001.4912 - mae: 44.9064\n",
            "Epoch 141/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7389.2056 - mae: 43.6931\n",
            "Epoch 142/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9924.1416 - mae: 56.4815\n",
            "Epoch 143/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6220.1055 - mae: 40.6137\n",
            "Epoch 144/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6214.4429 - mae: 43.8539\n",
            "Epoch 145/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29586.7734 - mae: 49.7665\n",
            "Epoch 146/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7081.1279 - mae: 43.8618\n",
            "Epoch 147/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6767.1455 - mae: 41.2101\n",
            "Epoch 148/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6352.4751 - mae: 41.3558\n",
            "Epoch 149/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5974.2227 - mae: 38.2780\n",
            "Epoch 150/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3374.6260 - mae: 33.3297\n",
            "Epoch 151/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5156.8618 - mae: 42.4269\n",
            "Epoch 152/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 15519.6543 - mae: 41.3332\n",
            "Epoch 153/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5852.6440 - mae: 35.6053\n",
            "Epoch 154/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5616.1821 - mae: 42.5902\n",
            "Epoch 155/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5214.7480 - mae: 43.3757\n",
            "Epoch 156/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5123.1553 - mae: 39.9719\n",
            "Epoch 157/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5015.7593 - mae: 39.8075\n",
            "Epoch 158/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4228.5576 - mae: 31.7545\n",
            "Epoch 159/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 2817.9370 - mae: 29.6169\n",
            "Epoch 160/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7511.7354 - mae: 39.1143\n",
            "Epoch 161/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5551.3135 - mae: 37.0446\n",
            "Epoch 162/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7204.1079 - mae: 39.1437\n",
            "Epoch 163/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7319.5356 - mae: 42.7151\n",
            "Epoch 164/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4049.3625 - mae: 35.4379\n",
            "Epoch 165/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7652.8564 - mae: 41.0008\n",
            "Epoch 166/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5234.5981 - mae: 45.9556\n",
            "Epoch 167/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4931.6992 - mae: 42.4281\n",
            "Epoch 168/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4996.9419 - mae: 41.9154\n",
            "Epoch 169/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6773.6841 - mae: 49.0134\n",
            "Epoch 170/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3475.9973 - mae: 36.3937\n",
            "Epoch 171/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9959.1465 - mae: 42.3562\n",
            "Epoch 172/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5927.6348 - mae: 38.7162\n",
            "Epoch 173/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5085.1514 - mae: 32.0473\n",
            "Epoch 174/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4131.2310 - mae: 33.7960\n",
            "Epoch 175/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3438.5066 - mae: 30.5481\n",
            "Epoch 176/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3569.0217 - mae: 34.9470\n",
            "Epoch 177/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4181.4951 - mae: 34.5888\n",
            "Epoch 178/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4216.9307 - mae: 31.0439\n",
            "Epoch 179/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3106.0610 - mae: 30.2403\n",
            "Epoch 180/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3177.9263 - mae: 28.7539\n",
            "Epoch 181/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3566.7224 - mae: 30.6847\n",
            "Epoch 182/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1407.9230 - mae: 23.2572\n",
            "Epoch 183/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4180.6392 - mae: 29.0917\n",
            "Epoch 184/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5412.3203 - mae: 29.4703\n",
            "Epoch 185/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3454.1956 - mae: 25.6813\n",
            "Epoch 186/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3437.5488 - mae: 27.3402\n",
            "Epoch 187/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 2427.0549 - mae: 26.3517\n",
            "Epoch 188/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4447.1318 - mae: 39.0445\n",
            "Epoch 189/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1886.4983 - mae: 20.7990\n",
            "Epoch 190/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4260.6396 - mae: 24.0422\n",
            "Epoch 191/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3189.0513 - mae: 26.6140\n",
            "Epoch 192/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1952.1475 - mae: 27.2467\n",
            "Epoch 193/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4956.3286 - mae: 26.6782\n",
            "Epoch 194/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 2129.9568 - mae: 28.7963\n",
            "Epoch 195/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 2273.8777 - mae: 28.7881\n",
            "Epoch 196/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9032.8125 - mae: 27.6220\n",
            "Epoch 197/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1868.9978 - mae: 26.9622\n",
            "Epoch 198/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4409.1069 - mae: 30.3119\n",
            "Epoch 199/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 2416.5891 - mae: 23.3162\n",
            "Epoch 200/200\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 1631.4274 - mae: 23.1857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result33_m.best_score_, grid_result33_m.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZOJzGUWAWkk",
        "outputId": "d737153e-a5fc-49b3-a967-b2cae5fcb8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: -76.909940 using {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 200, 'neurons': 10, 'weight_constraint': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Earlier with :\n",
        "batch_size = [100, 200, 400]\n",
        "epochs = [1, 5, 10]\n",
        "result for batch/epoc was ::\n",
        "Best: -445778.532813 using {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 32, 'weight_constraint': 1}\n",
        "\n",
        "Now after batch increase & epoch ::\n",
        "batch_size = [10, 20, 50]\n",
        "epochs = [50, 100,200]   SCORES are ::\n",
        "Best: -76.909940 using {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 200, 'neurons': 10, 'weight_constraint': 3}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LRnnh1tiBcSv"
      }
    }
  ]
}