{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/THESHAMIK/Real-Life-Projects/blob/main/Deep_NN/KHDS_KerasTuner_Optimized_NN_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igEo-hgrOqvN"
      },
      "source": [
        "For RANSOM SEARCG optimization of hyper params for 1. No of Layer 2. No of Units/Neurons 3. Learning rate for epochs = 5 loss='mean_absolute_error',\n",
        "metrics=['mean_absolute_error'])..\n",
        "        \n",
        "HERE is the rsult::\n",
        "{'**num_layers': 1**4, 'units_0': 352, 'units_1': 160, **'learning_rate': 0.01**, 'units_2': 32, 'units_3': 32, 'units_4': 32, 'units_5': 32, 'units_6': 32, 'units_7': 32, 'units_8': 32, 'units_9': 32, 'units_10': 32, 'units_11': 32, 'units_12': 32, 'units_13': 32}\n",
        "[42]\n",
        "\n",
        "SCORE ==> Score: **1.871**707518895467\n",
        "lAYERS = 14 & lr = 0.01\n",
        "For EPOCHS = 50 instead of 5 above. All remaining same.. Here is result::\n",
        "\n",
        "Hyperparameters:\n",
        "num_layers: 15\n",
        "units_0: 448\n",
        "units_1: 96\n",
        "learning_rate: 0.0001\n",
        "units_2: 256\n",
        "units_3: 320\n",
        "units_4: 96\n",
        "units_5: 416\n",
        "units_6: 160\n",
        "units_7: 480\n",
        "units_8: 448\n",
        "units_9: 192\n",
        "units_10: 192\n",
        "units_11: 160\n",
        "units_12: 320\n",
        "units_13: 352\n",
        "units_14: 480\n",
        "units_15: 224\n",
        "units_16: 192\n",
        "units_17: 480\n",
        "units_18: 416\n",
        "**Score: 1.4620293**776194255 ==> BEST SCORE so far but with huge epoch plus took 1 hr run time.\n",
        "No of layers = 15, lr = 0.0001. No of units details are below ::\n",
        "\n",
        "{'num_layers': 15, 'units_0': 448, 'units_1': 96, 'learning_rate': 0.0001, 'units_2': 256, 'units_3': 320, 'units_4': 96, 'units_5': 416, 'units_6': 160, 'units_7': 480, 'units_8': 448, 'units_9': 192, 'units_10': 192, 'units_11': 160, 'units_12': 320, 'units_13': 352, 'units_14': 480, 'units_15': 224, 'units_16': 192, 'units_17': 480, 'units_18': 416}\n",
        "\n",
        "\n",
        "When same is run using HYPERBAND than Random Search for 1. No of Layer 2. No of Units/Neurons 3. Learning rate for epochs = 5 loss='mean_absolute_error',\n",
        "metrics=['mean_absolute_error'])..\n",
        "here is the result:\n",
        "\n",
        "{'num_layers': 5, 'units_0': 128, 'units_1': 64, 'learning_rate': 0.001, 'units_2': 128, 'units_3': 128, 'units_4': 352, 'units_5': 96, 'units_6': 416, 'units_7': 352, 'units_8': 480, 'tuner/epochs': 5, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
        "\n",
        "SCORE ==> Score: **1.918**519377708435\n",
        "layers= 5, LR = 0.001\n",
        "\n",
        "So RM performed better than HyperBand when it came to epoch =5\n",
        "\n",
        "Now we tried to find best BATCH & EPOCHS::\n",
        "Here : units=hp.Int(\"units\", min_value=32, max_value=512, step=32)\n",
        "\n",
        "Hyperparameters:\n",
        "units: 256\n",
        "batch_size: 16\n",
        "Score: 2.076444149017334\n",
        "{'units': 256, 'batch_size': 16} --> with epochs of 5 & batch size [16,32]\n",
        "\n",
        "Next pass where batch size updated to [10,20,30,40,50] from [16,32]. result is\n",
        "{'units': 288, 'batch_size': 10}\n",
        "Next let's increase epoch to 100 from 5 ==>\n",
        "{'units': 480, 'batch_size': 20}\n",
        "\n",
        "Next pass we introduced all 3==> UNITS, BATCH_SIZE, EPOCHS ::\n",
        "Trial summary\n",
        "Hyperparameters:\n",
        "units: 320\n",
        "batch_size: 30\n",
        "epochs: 40\n",
        "Score: 1.7455352544784546\n",
        "\n",
        "{'units': 320, 'batch_size': 30, 'epochs': 40}\n",
        "\n",
        "When alll remaning same epochs increaaed to [20,50,100,150,200]\n",
        "Score = 1.6\n",
        "Hyperparameters:\n",
        "units: 160\n",
        "batch_size: 10\n",
        "epochs: 50\n",
        "Score: 1.6814736127853394\n",
        "\n",
        "\n",
        "Let's increase No. of trails from 3 to 20. upto now every time no. of trail =3\n",
        "Trial summary\n",
        "Hyperparameters:\n",
        "units: 512\n",
        "batch_size: 10\n",
        "epochs: 150\n",
        "**Score: 1.54**53487634658813 ==> This is best SCORE so far above. becoz of max trails increased mainly.\n",
        "\n",
        "{'units': 512, 'batch_size': 10, 'epochs': 150}\n",
        "\n",
        "Now INTRODUCING LEARNING RATE ALSO keeping all factors above same including no. of trails = 20\n",
        "Best val_loss So Far: 1.424674153327942 ==> **BETTER score than 1.54** \n",
        "Hyperparameters:\n",
        "units: 384\n",
        "learning_rate: 0.01\n",
        "batch_size: 30\n",
        "epochs: 200\n",
        "Score: 1.424674153327942\n",
        "{'units': 384, 'learning_rate': 0.01, 'batch_size': 30, 'epochs': 200}\n",
        "\n",
        "Now lets try all toghether => No of layer + No of units+ LR + Batch+Epoch\n",
        "plus No. of trails = 50 from 20 above. lets see::\n",
        "\n",
        "Trial 50 Complete [00h 00m 42s]\n",
        "val_loss: 1.5179283618927002\n",
        "\n",
        "**Best val_loss So Far: 1.449507474899292**\n",
        "\n",
        "{**'num_layers': 10**, 'units_0': 384, 'units_1': 352, 'learning_rate': 0.0001, 'units_2': 352, 'units_3': 224, 'units_4': 384, 'units_5': 256, 'units_6': 192, 'units_7': 192, 'units_8': 192, 'units_9': 320, 'units_10': 256, 'units_11': 32, 'units_12': 352, 'units_13': 416, 'units_14': 64, 'units_15': 288, 'units_16': 96, **'batch_size': 30, 'epochs': 200**}\n",
        "\n",
        "Results summary\n",
        "Results in my_dir/tune_hypermodel\n",
        "Showing 10 best trials\n",
        "<keras_tuner.engine.objective.Objective object at 0x7f8cdd8a4dd0>\n",
        "Trial summary\n",
        "Hyperparameters:\n",
        "num_layers: 10\n",
        "units_0: 384\n",
        "units_1: 352\n",
        "learning_rate: 0.0001\n",
        "units_2: 352\n",
        "units_3: 224\n",
        "units_4: 384\n",
        "units_5: 256\n",
        "units_6: 192\n",
        "units_7: 192\n",
        "units_8: 192\n",
        "units_9: 320\n",
        "units_10: 256\n",
        "units_11: 32\n",
        "units_12: 352\n",
        "units_13: 416\n",
        "units_14: 64\n",
        "units_15: 288\n",
        "units_16: 96\n",
        "batch_size: 30\n",
        "epochs: 200\n",
        "Score: 1.449507474899292\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtBAGvv4-15J"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "#from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
        "from tensorflow.keras.optimizers import Adam ##because cannot import name 'Adam' from 'keras.optimizers'\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from math import floor\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "#from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.layers import LeakyReLU\n",
        "LeakyReLU = LeakyReLU(alpha=0.1)\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o82D96jQ-86C",
        "outputId": "be03a3ec-761b-41c2-f945-2e736895a005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 711 entries, 0 to 710\n",
            "Data columns (total 34 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   LABfeed Sulphur                            711 non-null    float64\n",
            " 1   T1 : FRESH FEED FLOW TO KHDS KGPerHour     711 non-null    float64\n",
            " 2   T1 : Reactor inlet temperature DEGC        711 non-null    float64\n",
            " 3   T1 : Hydrogen make-up flow NM3perHour      711 non-null    float64\n",
            " 4   T1 : Recycle hydrogen flow NM3perHour      711 non-null    float64\n",
            " 5   T1 : REACTOR OUTLET Temp DEGC              711 non-null    float64\n",
            " 6   T1 : REACTOR FEED INLET Pressure KGperCM2  711 non-null    float64\n",
            " 7   T1 : Cold separator pressure KGperCM2      711 non-null    float64\n",
            " 8   T1 : KERO FEED DENSITY KGperCM2            711 non-null    float64\n",
            " 9   T2 : FRESH FEED FLOW TO KHDS KGPerHour     711 non-null    float64\n",
            " 10  T2 : Reactor inlet temperature DEGC        711 non-null    float64\n",
            " 11  T2 : Hydrogen make-up flow NM3perHour      711 non-null    float64\n",
            " 12  T2 : Recycle hydrogen flow NM3perHour      711 non-null    float64\n",
            " 13  T2 : REACTOR OUTLET Temp DEGC              711 non-null    float64\n",
            " 14  T2 : REACTOR FEED INLET Pressure KGperCM2  711 non-null    float64\n",
            " 15  T2 : Cold separator pressure KGperCM2      711 non-null    float64\n",
            " 16  T2 : KERO FEED DENSITY KGperCM2            711 non-null    float64\n",
            " 17  T3 : FRESH FEED FLOW TO KHDS KGPerHour     711 non-null    float64\n",
            " 18  T3 : Reactor inlet temperature DEGC        711 non-null    float64\n",
            " 19  T3 : Hydrogen make-up flow NM3perHour      711 non-null    float64\n",
            " 20  T3 : Recycle hydrogen flow NM3perHour      711 non-null    float64\n",
            " 21  T3 : REACTOR OUTLET Temp DEGC              711 non-null    float64\n",
            " 22  T3 : REACTOR FEED INLET Pressure KGperCM2  711 non-null    float64\n",
            " 23  T3 : Cold separator pressure KGperCM2      711 non-null    float64\n",
            " 24  T3 : KERO FEED DENSITY KGperCM2            711 non-null    float64\n",
            " 25  T4 : FRESH FEED FLOW TO KHDS KGPerHour     711 non-null    float64\n",
            " 26  T4 : Reactor inlet temperature DEGC        711 non-null    float64\n",
            " 27  T4 : Hydrogen make-up flow NM3perHour      711 non-null    float64\n",
            " 28  T4 : Recycle hydrogen flow NM3perHour      711 non-null    float64\n",
            " 29  T4 : REACTOR OUTLET Temp DEGC              711 non-null    float64\n",
            " 30  T4 : REACTOR FEED INLET Pressure KGperCM2  711 non-null    float64\n",
            " 31  T4 : Cold separator pressure KGperCM2      711 non-null    float64\n",
            " 32  T4 : KERO FEED DENSITY KGperCM2            711 non-null    float64\n",
            " 33  Product Sulphur                            711 non-null    float64\n",
            "dtypes: float64(34)\n",
            "memory usage: 194.4 KB\n"
          ]
        }
      ],
      "source": [
        "  df = pd.read_csv(\"khds_final_1.csv\")\n",
        "  df['Product Sulphur'] = pd.to_numeric(df['Product Sulphur'],errors = 'coerce') ##==> This one works as pd.to_numeric works for convert a list, a series, an array, or a tuple to a numeric datatype\n",
        "  filtered_df = df[df['Product Sulphur'].notnull()]\n",
        "  df.dropna(axis=0)\n",
        "  filtered_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MeYcDRC_HbV"
      },
      "outputs": [],
      "source": [
        "target_col = \"Product Sulphur\"\n",
        "X = filtered_df.loc[:, filtered_df.columns != target_col]\n",
        "y = filtered_df.loc[:, target_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.20, \n",
        "                                                    random_state=2021)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTKC2NDF_K6-",
        "outputId": "ef9f882e-61f2-4b46-c14c-6b47d4ffa9e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XTRAIN :: ytrain shapes::(568, 33, 568)\n"
          ]
        }
      ],
      "source": [
        "print(\"XTRAIN :: ytrain shapes::\"+ str(X_train.shape + y_train.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgpYUABK_QoN"
      },
      "outputs": [],
      "source": [
        "#Scale data, otherwise model will fail.\n",
        "#Standardize features by removing the mean and scaling to unit variance\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k61XetC_tXV",
        "outputId": "6b5f5162-b443-4ec7-8e92-d20daf9d9193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 81 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.2 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MMnuVBr_VCT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEWEpbck_0iO"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    for i in range(hp.Int('num_layers', 2, 20)):\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                                            min_value=32,\n",
        "                                            max_value=512,\n",
        "                                            step=32),\n",
        "                               activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='linear'))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "        loss='mean_absolute_error',\n",
        "        metrics=['mean_absolute_error'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v5jLwkhkTO0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyZItc4tAthO",
        "outputId": "c1a6f027-ac30-4ec7-f733-61aa9e8b3c1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project project/Air Quality Index/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from project/Air Quality Index/tuner0.json\n"
          ]
        }
      ],
      "source": [
        "tuner_RS = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_mean_absolute_error',\n",
        "    max_trials=50,\n",
        "    executions_per_trial=3,\n",
        "    directory='project',\n",
        "    project_name='Air Quality Index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7zrhFXIGSUY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxnxWQQ9Au7M",
        "outputId": "bf12dde6-d928-4796-f1cf-faf6e22de017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 19\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
            "units_2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_3 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_4 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_5 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_6 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_7 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_8 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_9 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_10 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_11 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_12 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_13 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_14 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_15 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_16 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n"
          ]
        }
      ],
      "source": [
        "tuner_RS.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixCrf_aeBKD0"
      },
      "outputs": [],
      "source": [
        "tuner_RS.search(X_train_scaled, y_train,\n",
        "             epochs=50,\n",
        "             validation_data=(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_FNWVUnBd_v",
        "outputId": "3f09a132-969e-4ef2-a9dc-d655943fcca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in project/Air Quality Index\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f8cdd9e9990>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 15\n",
            "units_0: 448\n",
            "units_1: 96\n",
            "learning_rate: 0.0001\n",
            "units_2: 256\n",
            "units_3: 320\n",
            "units_4: 96\n",
            "units_5: 416\n",
            "units_6: 160\n",
            "units_7: 480\n",
            "units_8: 448\n",
            "units_9: 192\n",
            "units_10: 192\n",
            "units_11: 160\n",
            "units_12: 320\n",
            "units_13: 352\n",
            "units_14: 480\n",
            "units_15: 224\n",
            "units_16: 192\n",
            "units_17: 480\n",
            "units_18: 416\n",
            "Score: 1.4620293776194255\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 15\n",
            "units_0: 384\n",
            "units_1: 192\n",
            "learning_rate: 0.0001\n",
            "units_2: 288\n",
            "units_3: 320\n",
            "units_4: 160\n",
            "units_5: 512\n",
            "units_6: 320\n",
            "units_7: 320\n",
            "units_8: 384\n",
            "units_9: 416\n",
            "units_10: 96\n",
            "units_11: 128\n",
            "units_12: 288\n",
            "units_13: 448\n",
            "units_14: 64\n",
            "units_15: 224\n",
            "units_16: 64\n",
            "units_17: 352\n",
            "units_18: 128\n",
            "Score: 1.476957082748413\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 11\n",
            "units_0: 352\n",
            "units_1: 224\n",
            "learning_rate: 0.0001\n",
            "units_2: 224\n",
            "units_3: 192\n",
            "units_4: 160\n",
            "units_5: 448\n",
            "units_6: 288\n",
            "units_7: 384\n",
            "units_8: 128\n",
            "units_9: 416\n",
            "units_10: 352\n",
            "units_11: 192\n",
            "units_12: 448\n",
            "units_13: 128\n",
            "units_14: 416\n",
            "units_15: 128\n",
            "units_16: 384\n",
            "units_17: 384\n",
            "units_18: 384\n",
            "Score: 1.4773924748102825\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 7\n",
            "units_0: 160\n",
            "units_1: 384\n",
            "learning_rate: 0.001\n",
            "units_2: 64\n",
            "units_3: 448\n",
            "units_4: 96\n",
            "units_5: 96\n",
            "units_6: 96\n",
            "units_7: 448\n",
            "units_8: 128\n",
            "units_9: 128\n",
            "units_10: 416\n",
            "units_11: 256\n",
            "units_12: 256\n",
            "units_13: 384\n",
            "units_14: 352\n",
            "units_15: 96\n",
            "units_16: 320\n",
            "units_17: 448\n",
            "units_18: 224\n",
            "Score: 1.4848633607228596\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 8\n",
            "units_0: 352\n",
            "units_1: 352\n",
            "learning_rate: 0.0001\n",
            "units_2: 384\n",
            "units_3: 352\n",
            "units_4: 32\n",
            "units_5: 320\n",
            "units_6: 352\n",
            "units_7: 64\n",
            "units_8: 224\n",
            "units_9: 128\n",
            "units_10: 352\n",
            "units_11: 320\n",
            "units_12: 352\n",
            "units_13: 416\n",
            "units_14: 352\n",
            "units_15: 480\n",
            "units_16: 480\n",
            "units_17: 448\n",
            "units_18: 224\n",
            "Score: 1.4864267508188884\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 15\n",
            "units_0: 352\n",
            "units_1: 320\n",
            "learning_rate: 0.0001\n",
            "units_2: 224\n",
            "units_3: 384\n",
            "units_4: 256\n",
            "units_5: 192\n",
            "units_6: 192\n",
            "units_7: 192\n",
            "units_8: 320\n",
            "units_9: 256\n",
            "units_10: 32\n",
            "units_11: 352\n",
            "units_12: 416\n",
            "units_13: 64\n",
            "units_14: 288\n",
            "units_15: 96\n",
            "units_16: 384\n",
            "units_17: 448\n",
            "units_18: 288\n",
            "Score: 1.4873417218526204\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 17\n",
            "units_0: 128\n",
            "units_1: 320\n",
            "learning_rate: 0.0001\n",
            "units_2: 416\n",
            "units_3: 160\n",
            "units_4: 320\n",
            "units_5: 128\n",
            "units_6: 32\n",
            "units_7: 384\n",
            "units_8: 384\n",
            "units_9: 128\n",
            "units_10: 352\n",
            "units_11: 128\n",
            "units_12: 224\n",
            "units_13: 160\n",
            "units_14: 352\n",
            "units_15: 416\n",
            "units_16: 320\n",
            "units_17: 192\n",
            "units_18: 128\n",
            "Score: 1.4908545811971028\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 15\n",
            "units_0: 224\n",
            "units_1: 384\n",
            "learning_rate: 0.001\n",
            "units_2: 160\n",
            "units_3: 192\n",
            "units_4: 256\n",
            "units_5: 224\n",
            "units_6: 256\n",
            "units_7: 160\n",
            "units_8: 32\n",
            "units_9: 256\n",
            "units_10: 352\n",
            "units_11: 160\n",
            "units_12: 512\n",
            "units_13: 32\n",
            "units_14: 448\n",
            "units_15: 352\n",
            "units_16: 320\n",
            "units_17: 32\n",
            "Score: 1.4924652179082234\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 10\n",
            "units_0: 416\n",
            "units_1: 384\n",
            "learning_rate: 0.001\n",
            "units_2: 480\n",
            "units_3: 320\n",
            "units_4: 448\n",
            "units_5: 320\n",
            "units_6: 448\n",
            "units_7: 224\n",
            "units_8: 96\n",
            "units_9: 256\n",
            "units_10: 448\n",
            "units_11: 128\n",
            "units_12: 320\n",
            "units_13: 256\n",
            "units_14: 256\n",
            "units_15: 224\n",
            "units_16: 224\n",
            "units_17: 320\n",
            "Score: 1.4931495189666748\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 17\n",
            "units_0: 320\n",
            "units_1: 448\n",
            "learning_rate: 0.001\n",
            "units_2: 320\n",
            "units_3: 192\n",
            "units_4: 128\n",
            "units_5: 320\n",
            "units_6: 288\n",
            "units_7: 192\n",
            "units_8: 256\n",
            "units_9: 352\n",
            "units_10: 32\n",
            "units_11: 128\n",
            "units_12: 160\n",
            "units_13: 416\n",
            "units_14: 32\n",
            "units_15: 288\n",
            "units_16: 64\n",
            "units_17: 384\n",
            "units_18: 32\n",
            "Score: 1.497507373491923\n"
          ]
        }
      ],
      "source": [
        "tuner_RS.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih_jHLS-Epi0"
      },
      "source": [
        "First PASS where HP used to find best no of layers + No of Neurons in each layer + Learning rate::\n",
        "Results summary\n",
        "Results in project/Air Quality Index\n",
        "Showing 10 best trials\n",
        "<keras_tuner.engine.objective.Objective object at 0x7f8ce0c6ba90>\n",
        "Trial summary\n",
        "Hyperparameters:\n",
        "num_layers: 14\n",
        "units_0: 352\n",
        "units_1: 160\n",
        "learning_rate: 0.01\n",
        "units_2: 32\n",
        "units_3: 32\n",
        "units_4: 32\n",
        "units_5: 32\n",
        "units_6: 32\n",
        "units_7: 32\n",
        "units_8: 32\n",
        "units_9: 32\n",
        "units_10: 32\n",
        "units_11: 32\n",
        "units_12: 32\n",
        "units_13: 32\n",
        "Score: 1.871707518895467\n",
        "Trial summary\n",
        "Hyperparameters:\n",
        "num_layers: 8\n",
        "units_0: 256\n",
        "units_1: 320\n",
        "learning_rate: 0.001\n",
        "units_2: 320\n",
        "units_3: 96\n",
        "units_4: 64\n",
        "units_5: 288\n",
        "units_6: 128\n",
        "units_7: 352\n",
        "units_8: 288\n",
        "units_9: 128\n",
        "units_10: 320\n",
        "units_11: 128\n",
        "units_12: 416\n",
        "units_13: 320\n",
        "Score: 1.8797086079915364"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDPQWlQKNqxl"
      },
      "outputs": [],
      "source": [
        "best_hps_RS = tuner_RS.get_best_hyperparameters()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRUfROWPNq5k",
        "outputId": "330ad86f-cf36-4d94-cb48-3303c5398a7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_layers': 15, 'units_0': 448, 'units_1': 96, 'learning_rate': 0.0001, 'units_2': 256, 'units_3': 320, 'units_4': 96, 'units_5': 416, 'units_6': 160, 'units_7': 480, 'units_8': 448, 'units_9': 192, 'units_10': 192, 'units_11': 160, 'units_12': 320, 'units_13': 352, 'units_14': 480, 'units_15': 224, 'units_16': 192, 'units_17': 480, 'units_18': 416}\n"
          ]
        }
      ],
      "source": [
        "print(best_hps_RS.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfYc0Ej0NrBF",
        "outputId": "a3a25d4c-cb45-494b-9d21-051f98d1e67a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0001\n"
          ]
        }
      ],
      "source": [
        "print(best_hps_RS.get('learning_rate'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfbsndyXKP-9",
        "outputId": "b5424cf8-1c6d-4565-d32f-220d5ee445f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n"
          ]
        }
      ],
      "source": [
        "#num_layers\n",
        "print(best_hps_RS.get('num_layers'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFEmJbysONh0",
        "outputId": "4a799dbf-dd8d-4321-c5a6-2e2b76eb920b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "352\n"
          ]
        }
      ],
      "source": [
        "print(best_hps_RS.get('units_13'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbM7X-PPN7-d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNbWVq7GG6X1"
      },
      "source": [
        "Now instead of RANDOM search lets use another HyperBand with same params like epochs =5, facotr =3 & objective val_mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcPlzH2KEyF7"
      },
      "outputs": [],
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "tuner = Hyperband(build_model, objective='val_mean_absolute_error',max_epochs=5, factor=3, directory = \"mydir\", project_name = \"my_tuner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL5A1Fn5GTas",
        "outputId": "f4f1073c-d9d8-4af3-e867-cfe6cad2765e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        }
      ],
      "source": [
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTjpYMxoKYXk",
        "outputId": "c043f141-cae7-479e-84fb-33fc5b54e5e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 00m 03s]\n",
            "val_mean_absolute_error: 2.007969379425049\n",
            "\n",
            "Best val_mean_absolute_error So Far: 1.918519377708435\n",
            "Total elapsed time: 00h 00m 21s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "tuner.search(X_train_scaled, y_train,\n",
        "             epochs=5,\n",
        "             validation_data=(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bMsuHIDHN5U",
        "outputId": "5363fb8c-1865-4a89-93f8-cce0b07a9f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in mydir/my_tuner\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f8cdbf5c110>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 5\n",
            "units_0: 128\n",
            "units_1: 64\n",
            "learning_rate: 0.001\n",
            "units_2: 128\n",
            "units_3: 128\n",
            "units_4: 352\n",
            "units_5: 96\n",
            "units_6: 416\n",
            "units_7: 352\n",
            "units_8: 480\n",
            "tuner/epochs: 5\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 1.918519377708435\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 7\n",
            "units_0: 448\n",
            "units_1: 352\n",
            "learning_rate: 0.01\n",
            "units_2: 224\n",
            "units_3: 224\n",
            "units_4: 128\n",
            "units_5: 224\n",
            "units_6: 288\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 1.9885259866714478\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 19\n",
            "units_0: 416\n",
            "units_1: 320\n",
            "learning_rate: 0.001\n",
            "units_2: 512\n",
            "units_3: 416\n",
            "units_4: 256\n",
            "units_5: 64\n",
            "units_6: 224\n",
            "units_7: 160\n",
            "units_8: 384\n",
            "tuner/epochs: 5\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "units_9: 32\n",
            "units_10: 32\n",
            "units_11: 32\n",
            "units_12: 32\n",
            "units_13: 32\n",
            "units_14: 32\n",
            "units_15: 32\n",
            "units_16: 32\n",
            "units_17: 32\n",
            "units_18: 32\n",
            "Score: 2.0072877407073975\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 12\n",
            "units_0: 384\n",
            "units_1: 288\n",
            "learning_rate: 0.01\n",
            "units_2: 512\n",
            "units_3: 416\n",
            "units_4: 448\n",
            "units_5: 224\n",
            "units_6: 288\n",
            "units_7: 320\n",
            "units_8: 320\n",
            "units_9: 256\n",
            "units_10: 128\n",
            "units_11: 64\n",
            "units_12: 160\n",
            "units_13: 128\n",
            "units_14: 448\n",
            "units_15: 96\n",
            "units_16: 320\n",
            "units_17: 416\n",
            "units_18: 32\n",
            "tuner/epochs: 5\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 2.007969379425049\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 7\n",
            "units_0: 448\n",
            "units_1: 352\n",
            "learning_rate: 0.01\n",
            "units_2: 224\n",
            "units_3: 224\n",
            "units_4: 128\n",
            "units_5: 224\n",
            "units_6: 288\n",
            "tuner/epochs: 5\n",
            "tuner/initial_epoch: 2\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0002\n",
            "Score: 2.087135076522827\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 4\n",
            "units_0: 448\n",
            "units_1: 288\n",
            "learning_rate: 0.0001\n",
            "units_2: 64\n",
            "units_3: 192\n",
            "units_4: 256\n",
            "units_5: 480\n",
            "units_6: 480\n",
            "tuner/epochs: 5\n",
            "tuner/initial_epoch: 2\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0001\n",
            "Score: 2.7649405002593994\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 4\n",
            "units_0: 448\n",
            "units_1: 288\n",
            "learning_rate: 0.0001\n",
            "units_2: 64\n",
            "units_3: 192\n",
            "units_4: 256\n",
            "units_5: 480\n",
            "units_6: 480\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 3.531177043914795\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 8\n",
            "units_0: 416\n",
            "units_1: 352\n",
            "learning_rate: 0.0001\n",
            "units_2: 96\n",
            "units_3: 224\n",
            "units_4: 224\n",
            "units_5: 96\n",
            "units_6: 416\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "units_7: 32\n",
            "Score: 3.5411674976348877\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 9\n",
            "units_0: 256\n",
            "units_1: 288\n",
            "learning_rate: 0.0001\n",
            "units_2: 64\n",
            "units_3: 416\n",
            "units_4: 192\n",
            "units_5: 128\n",
            "units_6: 96\n",
            "units_7: 192\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "units_8: 32\n",
            "Score: 3.5469698905944824\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 7\n",
            "units_0: 64\n",
            "units_1: 480\n",
            "learning_rate: 0.0001\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "units_2: 32\n",
            "units_3: 32\n",
            "units_4: 32\n",
            "units_5: 32\n",
            "units_6: 32\n",
            "Score: 4.044762134552002\n"
          ]
        }
      ],
      "source": [
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eVuNBN_HVkl"
      },
      "outputs": [],
      "source": [
        "best_hps = tuner.get_best_hyperparameters()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A_oz2uXL4fT",
        "outputId": "3d18e61f-7876-4564-de9e-0f1b77293eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_layers': 5, 'units_0': 128, 'units_1': 64, 'learning_rate': 0.001, 'units_2': 128, 'units_3': 128, 'units_4': 352, 'units_5': 96, 'units_6': 416, 'units_7': 352, 'units_8': 480, 'tuner/epochs': 5, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n"
          ]
        }
      ],
      "source": [
        "print(best_hps.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_1BdKKrMCLD",
        "outputId": "4c42a39d-e11e-4be8-ac40-9394740c1d99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.001\n"
          ]
        }
      ],
      "source": [
        "print(best_hps.get('learning_rate'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaZOMN8iMO_-",
        "outputId": "3dad50be-ed97-4e9e-d02d-d90db3ceedfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "#num_layers\n",
        "print(best_hps.get('num_layers'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMF2rAbrLpju",
        "outputId": "ee95aab1-a340-42bd-9c81-2c066a47a3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64\n"
          ]
        }
      ],
      "source": [
        "print(best_hps.get('units_1'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt4oUX9sjulQ"
      },
      "source": [
        "Trying for further ways to get BEST of BATCH & EPOCH also. Apve we got no of units, layer & LR.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHJMpJv9ngql"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTBWjrFBxqun"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    for i in range(hp.Int('num_layers', 2, 20)):\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                                            min_value=32,\n",
        "                                            max_value=512,\n",
        "                                            step=32),\n",
        "                               activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='linear'))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "        loss='mean_absolute_error',\n",
        "        metrics=['mean_absolute_error'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SXGISZhjuDw"
      },
      "outputs": [],
      "source": [
        "class MyHyperModel(kt.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = keras.Sequential()\n",
        "        model.add(\n",
        "            layers.Dense(\n",
        "                units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "                activation=\"relu\",\n",
        "            )\n",
        "        )\n",
        "        model.add(layers.Dense(1, activation='linear'))\n",
        "        model.compile(keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), loss=\"mean_absolute_error\", metrics=[\"mean_absolute_error\"])\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        return model.fit(\n",
        "            *args,\n",
        "            batch_size=hp.Choice(\"batch_size\", [10, 20, 30]),\n",
        "            epochs=hp.Choice(\"epochs\", [20, 50, 100, 150, 200]),\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "tuner12 = kt.RandomSearch(\n",
        "    MyHyperModel(),\n",
        "    objective=\"val_loss\",\n",
        "    max_trials=3,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"tune_hypermodel\",\n",
        ")\n",
        "\n",
        "tuner13 = kt.RandomSearch(\n",
        "    MyHyperModel(),\n",
        "    objective=\"val_loss\",\n",
        "    max_trials=20,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"tune_hypermodel\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gULRygbBwMGv"
      },
      "source": [
        "https://github.com/keras-team/keras-tuner/issues/122 ==> This site was used to introduce both batch_size & epochs. Uptil now only No. of units + no of layers+ LR was used as hyper params."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "izIROpx9pC3X",
        "outputId": "2548ea92-c329-48f4-e4b2-808602eefc36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "224               |?                 |units\n",
            "\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-2c313674e6cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tuner12.search(X_train_scaled, y_train,\n\u001b[1;32m      2\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m              validation_data=(X_test_scaled, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         return tuner_utils.convert_to_metrics_dict(\n\u001b[1;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-109-ceccdeafe844>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mepoch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         )\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'epoch_size'"
          ]
        }
      ],
      "source": [
        "tuner12.search(X_train_scaled, y_train,\n",
        "             epochs=100,\n",
        "             validation_data=(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUNRsmH_s7cI",
        "outputId": "d2eee4f7-6d44-4bea-9f73-cd0c02f0fd66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 20 Complete [00h 00m 17s]\n",
            "val_loss: 1.587787389755249\n",
            "\n",
            "Best val_loss So Far: 1.424674153327942\n",
            "Total elapsed time: 00h 04m 45s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "tuner13.search(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt5kEgZutVoH",
        "outputId": "eb82561f-4ae5-47ac-d441-0552c84d3afc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in my_dir/tune_hypermodel\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f8cdc0b2dd0>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 384\n",
            "learning_rate: 0.01\n",
            "batch_size: 30\n",
            "epochs: 200\n",
            "Score: 1.424674153327942\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 384\n",
            "learning_rate: 0.01\n",
            "batch_size: 20\n",
            "epochs: 150\n",
            "Score: 1.4786961078643799\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 352\n",
            "learning_rate: 0.01\n",
            "batch_size: 30\n",
            "epochs: 150\n",
            "Score: 1.503404140472412\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 128\n",
            "learning_rate: 0.01\n",
            "batch_size: 10\n",
            "epochs: 100\n",
            "Score: 1.52353835105896\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 256\n",
            "learning_rate: 0.01\n",
            "batch_size: 30\n",
            "epochs: 100\n",
            "Score: 1.5681228637695312\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 224\n",
            "learning_rate: 0.001\n",
            "batch_size: 10\n",
            "epochs: 150\n",
            "Score: 1.5746618509292603\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 256\n",
            "learning_rate: 0.001\n",
            "batch_size: 30\n",
            "epochs: 150\n",
            "Score: 1.586961030960083\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 160\n",
            "learning_rate: 0.001\n",
            "batch_size: 30\n",
            "epochs: 200\n",
            "Score: 1.587787389755249\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 32\n",
            "learning_rate: 0.01\n",
            "batch_size: 20\n",
            "epochs: 100\n",
            "Score: 1.63973867893219\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "learning_rate: 0.01\n",
            "batch_size: 10\n",
            "epochs: 50\n",
            "Score: 1.6426371335983276\n"
          ]
        }
      ],
      "source": [
        "tuner13.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NbKjiBUtVsX"
      },
      "outputs": [],
      "source": [
        "best_hps13 = tuner13.get_best_hyperparameters()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zlv4HlstVwA",
        "outputId": "ce35bf0a-391a-480b-c97b-7226a3ed074c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'units': 384, 'learning_rate': 0.01, 'batch_size': 30, 'epochs': 200}\n"
          ]
        }
      ],
      "source": [
        "print(best_hps13.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOy1iCXutVyq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHk5QSqltV1Z"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUrTSbf_tV4P"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6MnvWQ9kUjz",
        "outputId": "d22239c5-0f71-400b-bbb3-2e3b5e1e8a9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in my_dir/tune_hypermodel\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f8cdd94e690>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 480\n",
            "batch_size: 20\n",
            "Score: 1.6014951467514038\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 448\n",
            "batch_size: 30\n",
            "Score: 1.6128138303756714\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 96\n",
            "batch_size: 10\n",
            "Score: 1.6176576614379883\n"
          ]
        }
      ],
      "source": [
        "tuner12.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hsJH6SApgmU"
      },
      "outputs": [],
      "source": [
        "best_hps12 = tuner12.get_best_hyperparameters()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5QMy2cVpgzU",
        "outputId": "e784869c-a3e0-4138-e868-69ab217fef9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'units': 480, 'batch_size': 20}\n"
          ]
        }
      ],
      "source": [
        "print(best_hps12.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "BIHD2jRMp3Kp",
        "outputId": "d4d88e49-067d-4f87-e409-29088c69fad1"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-fa03002dc8d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} is currently inactive.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} does not exist.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'batch_size does not exist.'"
          ]
        }
      ],
      "source": [
        "print(best_hps.get('batch_size'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsYMefL5qUc9"
      },
      "outputs": [],
      "source": [
        "class MyHyperModel(kt.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = keras.Sequential()\n",
        "        for i in range(hp.Int('num_layers', 2, 20)):\n",
        "          model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                                            min_value=32,\n",
        "                                            max_value=512,\n",
        "                                            step=32),\n",
        "                               activation='relu'))\n",
        "        model.add(layers.Dense(1, activation='linear'))\n",
        "        model.compile(keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), loss=\"mean_absolute_error\", metrics=[\"mean_absolute_error\"])\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        return model.fit(\n",
        "            *args,\n",
        "            batch_size=hp.Choice(\"batch_size\", [10, 20, 30]),\n",
        "            epochs=hp.Choice(\"epochs\", [20, 50, 100, 150, 200]),\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "tuner12 = kt.RandomSearch(\n",
        "    MyHyperModel(),\n",
        "    objective=\"val_loss\",\n",
        "    max_trials=3,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"tune_hypermodel\",\n",
        ")\n",
        "\n",
        "tuner13 = kt.RandomSearch(\n",
        "    MyHyperModel(),\n",
        "    objective=\"val_loss\",\n",
        "    max_trials=20,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"tune_hypermodel\",\n",
        ")\n",
        "\n",
        "tuner_final = kt.RandomSearch(\n",
        "    MyHyperModel(),\n",
        "    objective=\"val_loss\",\n",
        "    max_trials=50,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"tune_hypermodel\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGtv8jt1qUhl",
        "outputId": "9784a037-665f-463a-921a-0bcdbc080e22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 50 Complete [00h 00m 42s]\n",
            "val_loss: 1.5179283618927002\n",
            "\n",
            "Best val_loss So Far: 1.449507474899292\n",
            "Total elapsed time: 00h 36m 23s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "tuner_final.search(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r-tQIk6qUll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8181df7e-bd01-4336-ff9c-7f00c8686b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in my_dir/tune_hypermodel\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f8cdd8a4dd0>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 10\n",
            "units_0: 384\n",
            "units_1: 352\n",
            "learning_rate: 0.0001\n",
            "units_2: 352\n",
            "units_3: 224\n",
            "units_4: 384\n",
            "units_5: 256\n",
            "units_6: 192\n",
            "units_7: 192\n",
            "units_8: 192\n",
            "units_9: 320\n",
            "units_10: 256\n",
            "units_11: 32\n",
            "units_12: 352\n",
            "units_13: 416\n",
            "units_14: 64\n",
            "units_15: 288\n",
            "units_16: 96\n",
            "batch_size: 30\n",
            "epochs: 200\n",
            "Score: 1.449507474899292\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 13\n",
            "units_0: 416\n",
            "units_1: 416\n",
            "learning_rate: 0.001\n",
            "units_2: 128\n",
            "units_3: 448\n",
            "units_4: 352\n",
            "units_5: 288\n",
            "units_6: 352\n",
            "units_7: 192\n",
            "units_8: 480\n",
            "units_9: 128\n",
            "units_10: 160\n",
            "units_11: 320\n",
            "units_12: 128\n",
            "units_13: 32\n",
            "units_14: 480\n",
            "units_15: 224\n",
            "units_16: 96\n",
            "batch_size: 20\n",
            "epochs: 50\n",
            "units_17: 32\n",
            "Score: 1.4515553712844849\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_0: 416\n",
            "units_1: 96\n",
            "learning_rate: 0.001\n",
            "units_2: 160\n",
            "units_3: 256\n",
            "units_4: 448\n",
            "units_5: 32\n",
            "units_6: 32\n",
            "units_7: 448\n",
            "units_8: 256\n",
            "units_9: 384\n",
            "units_10: 480\n",
            "units_11: 224\n",
            "units_12: 224\n",
            "units_13: 96\n",
            "units_14: 32\n",
            "units_15: 288\n",
            "units_16: 448\n",
            "batch_size: 30\n",
            "epochs: 50\n",
            "Score: 1.4520282745361328\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 16\n",
            "units_0: 448\n",
            "units_1: 480\n",
            "learning_rate: 0.0001\n",
            "units_2: 224\n",
            "units_3: 160\n",
            "units_4: 32\n",
            "units_5: 288\n",
            "units_6: 256\n",
            "units_7: 352\n",
            "units_8: 480\n",
            "units_9: 384\n",
            "units_10: 384\n",
            "units_11: 224\n",
            "units_12: 512\n",
            "units_13: 288\n",
            "units_14: 352\n",
            "units_15: 32\n",
            "units_16: 416\n",
            "batch_size: 10\n",
            "epochs: 200\n",
            "Score: 1.4558110237121582\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 6\n",
            "units_0: 352\n",
            "units_1: 160\n",
            "learning_rate: 0.001\n",
            "units_2: 480\n",
            "units_3: 224\n",
            "units_4: 448\n",
            "units_5: 128\n",
            "units_6: 320\n",
            "units_7: 448\n",
            "units_8: 384\n",
            "units_9: 128\n",
            "units_10: 512\n",
            "units_11: 448\n",
            "units_12: 416\n",
            "units_13: 32\n",
            "units_14: 512\n",
            "units_15: 128\n",
            "units_16: 160\n",
            "batch_size: 10\n",
            "epochs: 50\n",
            "Score: 1.464555025100708\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 6\n",
            "units_0: 320\n",
            "units_1: 160\n",
            "learning_rate: 0.0001\n",
            "units_2: 352\n",
            "units_3: 288\n",
            "units_4: 512\n",
            "units_5: 64\n",
            "units_6: 32\n",
            "units_7: 384\n",
            "units_8: 320\n",
            "units_9: 256\n",
            "units_10: 192\n",
            "units_11: 320\n",
            "units_12: 160\n",
            "units_13: 256\n",
            "units_14: 96\n",
            "units_15: 32\n",
            "units_16: 256\n",
            "batch_size: 10\n",
            "epochs: 50\n",
            "units_17: 352\n",
            "units_18: 160\n",
            "Score: 1.4656504392623901\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 18\n",
            "units_0: 224\n",
            "units_1: 224\n",
            "learning_rate: 0.0001\n",
            "units_2: 64\n",
            "units_3: 448\n",
            "units_4: 128\n",
            "units_5: 416\n",
            "units_6: 96\n",
            "units_7: 256\n",
            "units_8: 96\n",
            "units_9: 256\n",
            "units_10: 384\n",
            "units_11: 96\n",
            "units_12: 160\n",
            "units_13: 160\n",
            "units_14: 480\n",
            "units_15: 96\n",
            "units_16: 256\n",
            "batch_size: 30\n",
            "epochs: 50\n",
            "units_17: 512\n",
            "Score: 1.4784992933273315\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 12\n",
            "units_0: 480\n",
            "units_1: 256\n",
            "learning_rate: 0.0001\n",
            "units_2: 288\n",
            "units_3: 64\n",
            "units_4: 480\n",
            "units_5: 416\n",
            "units_6: 288\n",
            "units_7: 32\n",
            "units_8: 448\n",
            "units_9: 480\n",
            "units_10: 352\n",
            "units_11: 416\n",
            "units_12: 288\n",
            "units_13: 480\n",
            "units_14: 416\n",
            "units_15: 288\n",
            "units_16: 352\n",
            "batch_size: 10\n",
            "epochs: 50\n",
            "units_17: 64\n",
            "units_18: 448\n",
            "Score: 1.479693055152893\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 6\n",
            "units_0: 480\n",
            "units_1: 224\n",
            "learning_rate: 0.0001\n",
            "units_2: 416\n",
            "units_3: 64\n",
            "units_4: 128\n",
            "units_5: 128\n",
            "units_6: 128\n",
            "units_7: 256\n",
            "units_8: 192\n",
            "units_9: 320\n",
            "units_10: 224\n",
            "units_11: 448\n",
            "units_12: 32\n",
            "units_13: 384\n",
            "units_14: 160\n",
            "units_15: 352\n",
            "units_16: 480\n",
            "batch_size: 20\n",
            "epochs: 200\n",
            "units_17: 288\n",
            "Score: 1.482260823249817\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 15\n",
            "units_0: 160\n",
            "units_1: 160\n",
            "learning_rate: 0.0001\n",
            "units_2: 192\n",
            "units_3: 64\n",
            "units_4: 448\n",
            "units_5: 96\n",
            "units_6: 96\n",
            "units_7: 96\n",
            "units_8: 448\n",
            "units_9: 128\n",
            "units_10: 128\n",
            "units_11: 416\n",
            "units_12: 256\n",
            "units_13: 256\n",
            "units_14: 384\n",
            "units_15: 352\n",
            "units_16: 96\n",
            "batch_size: 30\n",
            "epochs: 200\n",
            "Score: 1.483767032623291\n"
          ]
        }
      ],
      "source": [
        "tuner_final.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ1tNN50qUo8"
      },
      "outputs": [],
      "source": [
        "best_hps_final = tuner_final.get_best_hyperparameters()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcyEORMpqUr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e35fd0b-881b-45ec-fe42-e17d370e8453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num_layers': 10, 'units_0': 384, 'units_1': 352, 'learning_rate': 0.0001, 'units_2': 352, 'units_3': 224, 'units_4': 384, 'units_5': 256, 'units_6': 192, 'units_7': 192, 'units_8': 192, 'units_9': 320, 'units_10': 256, 'units_11': 32, 'units_12': 352, 'units_13': 416, 'units_14': 64, 'units_15': 288, 'units_16': 96, 'batch_size': 30, 'epochs': 200}\n"
          ]
        }
      ],
      "source": [
        "print(best_hps_final.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KxgLMCFqUuZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7kYXmsLp3Of"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGFXNR9Spg7b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLz6wzPZllng"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY5lo-L5le_s"
      },
      "outputs": [],
      "source": [
        "class MyHyperModel(kt.HyperModel):\n",
        "    def build(self, hp):\n",
        "        \"\"\"Builds a convolutional model.\"\"\"\n",
        "        inputs = keras.Input(shape=(28, 28, 1))\n",
        "        x = keras.layers.Flatten()(inputs)\n",
        "        x = keras.layers.Dense(\n",
        "            units=hp.Choice(\"units\", [32, 64, 128]), activation=\"relu\"\n",
        "        )(x)\n",
        "        outputs = keras.layers.Dense(10)(x)\n",
        "        return keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    def fit(self, hp, model, x, y, validation_data, callbacks=None, **kwargs):\n",
        "        # Convert the datasets to tf.data.Dataset.\n",
        "        batch_size = hp.Int(\"batch_size\", 32, 128, step=32, default=64)\n",
        "        train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(\n",
        "            batch_size\n",
        "        )\n",
        "        validation_data = tf.data.Dataset.from_tensor_slices(validation_data).batch(\n",
        "            batch_size\n",
        "        )\n",
        "\n",
        "        # Define the optimizer.\n",
        "        optimizer = keras.optimizers.Adam(\n",
        "            hp.Float(\"learning_rate\", 1e-4, 1e-2, sampling=\"log\", default=1e-3)\n",
        "        )\n",
        "        loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "        # The metric to track validation loss.\n",
        "        epoch_loss_metric = keras.metrics.Mean()\n",
        "\n",
        "        # Function to run the train step.\n",
        "        @tf.function\n",
        "        def run_train_step(images, labels):\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = model(images)\n",
        "                loss = loss_fn(labels, logits)\n",
        "                # Add any regularization losses.\n",
        "                if model.losses:\n",
        "                    loss += tf.math.add_n(model.losses)\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        # Function to run the validation step.\n",
        "        @tf.function\n",
        "        def run_val_step(images, labels):\n",
        "            logits = model(images)\n",
        "            loss = loss_fn(labels, logits)\n",
        "            # Update the metric.\n",
        "            epoch_loss_metric.update_state(loss)\n",
        "\n",
        "        # Assign the model to the callbacks.\n",
        "        for callback in callbacks:\n",
        "            callback.model = model\n",
        "\n",
        "        # Record the best validation loss value\n",
        "        best_epoch_loss = float(\"inf\")\n",
        "\n",
        "        # The custom training loop.\n",
        "        for epoch in range(2):\n",
        "            print(f\"Epoch: {epoch}\")\n",
        "\n",
        "            # Iterate the training data to run the training step.\n",
        "            for images, labels in train_ds:\n",
        "                run_train_step(images, labels)\n",
        "\n",
        "            # Iterate the validation data to run the validation step.\n",
        "            for images, labels in validation_data:\n",
        "                run_val_step(images, labels)\n",
        "\n",
        "            # Calling the callbacks after epoch.\n",
        "            epoch_loss = float(epoch_loss_metric.result().numpy())\n",
        "            for callback in callbacks:\n",
        "                # The \"my_metric\" is the objective passed to the tuner.\n",
        "                callback.on_epoch_end(epoch, logs={\"my_metric\": epoch_loss})\n",
        "            epoch_loss_metric.reset_states()\n",
        "\n",
        "            print(f\"Epoch loss: {epoch_loss}\")\n",
        "            best_epoch_loss = min(best_epoch_loss, epoch_loss)\n",
        "\n",
        "        # Return the evaluation metric value.\n",
        "        return best_epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGGFEdqYmLUg"
      },
      "outputs": [],
      "source": [
        "tuner_11 = kt.RandomSearch(\n",
        "    objective=kt.Objective(\"my_metric\", \"min\"),\n",
        "    max_trials=2,\n",
        "    hypermodel=MyHyperModel(),\n",
        "    directory=\"results\",\n",
        "    project_name=\"custom_training\",\n",
        "    overwrite=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "PaSbOD0FmQ1W",
        "outputId": "bfb4254d-235e-41f4-d0a3-8671a921bb32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "128               |?                 |units\n",
            "64                |?                 |batch_size\n",
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-1cfd0fe00e87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tuner_11.search(X_train_scaled, y_train,\n\u001b[1;32m      2\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m              validation_data=(X_test_scaled, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         return tuner_utils.convert_to_metrics_dict(\n\u001b[1;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-12eaad8cb497>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, x, y, validation_data, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Convert the datasets to tf.data.Dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ],
      "source": [
        "tuner_11.search(X_train_scaled, y_train,\n",
        "             epochs=5,\n",
        "             validation_data=(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-HAeoKEm2SG"
      },
      "outputs": [],
      "source": [
        "tuner.search(X_train_scaled, y_train,\n",
        "             epochs=5,\n",
        "             validation_data=(X_test_scaled, y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "KHDS_KerasTuner_Optimized_NN_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNhoYayQ4nOByWnQgQp4HtO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}